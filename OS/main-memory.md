# 메인 메모리
## 💡 배경 _Background

> 전형적인 명령어 실행은 먼저 메모리로부터 한 명령어를 가져오는 데서부터 시작된다.
> 
- 그런 다음 명령어를 해독하고, 메모리에서 피연산자를 가져온다.
    - → 이후는 피연산자에 대해 명령어를 실행한 후에 계산 결과를 메모리에 저장한다.
    - ***메모리는 주소에 지시한 대로 읽기, 쓰기만 할 뿐 이 주소들이 어떻게 생성되었는지 모른다!***
    - 따라서 주소가 프로그램에 의해서 ***어떻게 생성되었는지***에 대한 세부 사항은 고려 대상이 아니다.

<br/>

<br/>

### 기본 하드웨어

> 메인 메모리와 각 처리 코어에 내장된 레지스터들은 CPU가 직접 접근할 수 있는 유일한 범용 저장장치다.
> 
- 기계 명령어들은 메모리 주소만을 인수로 취하고, 디스크의 주소를 인수로 취하지 않는다.
    - → 따라서 모든 실행되는 명령어와 데이터들은 CPU가 직접적으로 접근할 수 있는 메인 메모리와 레지스터에 있어야 한다!
        - 만약 데이터가 메모리에 없다면? → CPU가 처리하기 전에 메모리로 옮겨야 한다.

<br/>

<br/>

> 메인 메모리에 접근을 완료하기 위해서는 많은 CPU 클록 틱이 소요된다.
> 
- 이 경우 CPU가 필요한 데이터가 없어서 명령어를 수행하지 못하고 지연(stall)되는 현상이 발생한다.
    - 이러한 상황은 메인 메모리의 접근이 빈번하게 일어나는 경우에는 용납될 수 없다!
    - ***해결 방법 → CPU와 메인 메모리 사이에 빠른 속도의 메모리인 캐시를 추가하는 것이다.***

<br/>

<br/>

> 물리 메모리의 상대적인 접근 속도의 차이를 고려하는 것에 추가로 올바른 동작을 보장해야만 한다.
> 
- 시스템이 올바르게 동작하기 위해서는 사용자 프로그램으로부터 운영체제 영역을 보호해야 할 뿐만 아니라 사용자 프로그램 사이도 서로 보호해야 한다.
- 운영체제가 CPU와 메모리 간의 접근에 개입하면 성능이 떨어진다.
    - → 따라서 이러한 보호 기법은 반드시 하드웨어가 지원해야 한다.

<br/>

<br/>

> 먼저 각각의 프로세스가 독립된 메모리 공간을 가지도록 보장해야 한다.
> 
- 개별적인 프로세스별 메모리 공간은 서로를 보호하고 병행 실행을 위해 여러 프로세스가 메모리에 적재되게 하는 것이 필수다.
    - 개별적인 메모리 공간을 분리하려면?
        - 특정 프로세스만 접근할 수 있는 합법적인 메모리 주소 영역을 설정,
        - 프로세스가 합법적인 영역만을 접근하도록 하는 것이 필요하다.

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/base-limit-register.png" width = 500/>

> 기준(base)과 상한(limit)이라고 불리는 두 개의 레지스터들을 사용해 이러한 보호 기법을 제공한다.
> 
- **기준 레지스터**는 가장 작은 합법적인 물리 메모리 주소의 값을 저장하고,
- **상한 레지스터**는 주어진 영역의 크기를 설정한다.

<br/>

<br/>


<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/trap.png" width = 500/>

> 메모리 공간의 보호는 CPU 하드웨어가 사용자 모드에서 만들어진 모든 주소와 레지스터를 비교함으로써 이루어진다.
> 
- 사용자 모드에서 수행되는 프로그램이 운영체제의 메모리 공간이나 다른 사용자 메모리 공간에 접근하면?
    - → 운영체제는 치명적인 오류로 간주해 트랩(trap)을 발생시킨다.

<br/>

<br/>

> 기준과 상한 레지스터는 여러 가지 특권 명령을 사용하는 운영체제에 의해서만 적재된다.
> 
- → 이는 특권 명령은 오직 커널 모드에서만 수행되고, 운영체제만 커널 모드에서 수행되기 때문이다.
- 이러한 기법은 운영체제만 레지스터들의 값을 변경할 수 있도록 허가해 준다.

<br/>

<br/>

> 커널 모드에서 수행되는 운영체제는 메모리 영역의 접근에 어떠한 제약도 받지 않는다.
> 
- 이러한 원칙 덕에 운영체제는 사용자 프로그램을 사용자 메모리 영역에 적재하고,
    - 오류가 발생한 경우 그 프로그램을 덤프(dump out)하고,
    - 시스템 콜의 매개변수를 변경하는 등의 서비스가 가능하다.

<br/>

<br/>

### 주소의 할당

> 대부분의 시스템은  사용자 프로세스가 메모리 내 어느 부분으로도 올라올 수 있도록 지원한다.
> 
- = “사용자 프로세스 주소가 00000번지부터 시작된다해서 프로그램이 메모리에 00000번지부터 올라올 필요는 없다” 는 뜻이다.

<br/>

<br/>


<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/multistep.png" width = 500/>

> 대부분의 사용자 프로그램은 여러 단계를 거쳐 시행되기 때문에 여러 가지 다른 표현 방식을 거치게 된다.
> 
- 원시 프로그램에서 주소는 숫자가 아닌 심볼 형태로 표현된다.
    - ***컴파일러는 이  심볼 주소를 재배치 가능 주소로 바인딩시키고,***
    - ***다음에 링커나 로더가 재배치 가능 주소를 절대 주소로 바인딩시킨다!***

<br/>

<br/>

> 전통적으로 메모리 주소 공간에서 명령어와 데이터의 바인딩은 이루어지는 시점에 따라 구분된다.
> 
- ***컴파일 시간 바인딩***
    - 만일 프로세스가 메모리 내에 들어갈 위치를 컴파일 시간에 미리 알 수 있으면?
        - → 컴파일러는 **절대 코드**를 생성할 수 있다.

<br/>

<br/>

- ***적재 시간 바인딩***
    - 만일 프로세스가 메모리 내 어디로 올라오게 될지를 컴파일 시점에 알지 못하면 컴파일러는 일단 **이진 코드를 재배치 가능 코드로** 만들어야 한다.
        - → 이 경우 심볼과 진짜 번지수와의 바인딩은 프로그램이 메인 메모리로 실제로 적재되는 시간에 이루어진다.

<br/>

<br/>

- ***실행 시간 바인딩***
    - 만약 프로세스가 실행하는 중간에 메모리 내의 한 세그먼트로부터 다른 세그먼트로 옮겨질 수 있다면?
        - → 우리는 바인딩이  실행 시간까지 허용되었다고 이야기한다.

<br/>

<br/>

### 논리 대 물리 주소 공간

> CPU가 생성하는 주소 → **논리 주소**(`logical address`)
메모리가 취급하게 되는 주소 → **물리 주소**(`physical address`)
> 

<br/>

<br/>

> 컴파일 또는 적재 시에 주소를 바인딩하면 논리 주소와 물리 주소가 같다.
> 
- 그러나 실행 시간 바인딩 기법에서는 논리, 물리 주소가 다르다.
    - → 이러면 논리 주소를 **가상 주소**라 한다.
    - 이 책에서는 논리 주소나 가상 주소나 같은 뜻으로 사용한다.

<br/>

<br/>

> 프로그램에 의해 생성된 모든 논리 주소 집합 → **논리 주소 공간**
논리 주소와 일치하는 모든 물리 주소 집합 → **물리 주소 공간**
> 

<br/>

<br/>


<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/dynamic-relocate.png" width = 500/>

> **메모리 관리 장치**(MMU : Memory Management Unit)
> 
- 프로그램 실행 중에 가상 주소를 물리 주소로 바꾸어주는 변환 작업을 수행한다.

<br/>

<br/>

### 동적 적재

> 메모리 공간의 더 효율적인 이용을 위해서는 동적 적재를 해야 한다.
> 
- 동적 적재에서 각 루틴은 실제 호출되기 전까지는 메모리에 올라오지 않는다.
    - 이후, 호출됐는데 적재되어 있지 않다면 재배치 가능 연결 적재기가 불려 요구된 루틴을 메모리에 가져온다.

<br/>

<br/>

> 동적 적재의 장점
> 
- 루틴이 필요한 경우에만 적재된다!
    - ***이러한 구조는 오류 처리 루틴과 같이 아주 간혹 발생하면서도 실행할 코드가 많은 경우에 유용하다.***

<br/>

<br/>

## 동적 연결 및 공유 라이브러리

> **동적 연결 라이브러리**(DLL)이란?
> 
- 사용자 프로그램이 실행될 때, 사용자 프로그램에 연결되는 시스템 라이브러리이다.
- 동적 연결 개념은 동적 적재의 개념과 유사하다.
    - 동적 적재 → 로딩이 실행 시까지 미루어짐
    - 동적 연결 → 실행 시기까지 미루어짐

<br/>

<br/>

> DLL의 장점
> 
- 라이브러리를 여러 프로세스 간에 공유할 수 있다. → 메인 메모리에는 DLL 인스턴스가 하나!
    - 이러한 이유로 DLL은 **공유 라이브러리**라고도 한다.

<br/>

<br/>

> 동적 적재와는 달리 동적 연결과 공유 라이브러리는 일반적으로 운영체제의 도움이 필요하다.
> 
- 메모리에 있는 프로세스들이 각자의 공간은 자기만 액세스할 수 있도록 보호된다면?
    - → 운영체제만이 기억 공간에 루틴이 있는지를 검사해 줄 수 있고 운영체제만이 여러 프로세스가 같은 메모리 주소를 공용할 수 있도록 해줄 수 있다.

<br/>

<br/>

# 💡 연속 메모리 할당 _Contiguous Memory Allocation

> 메인 메모리는 운영체제 뿐만 아니라 여러 사용자 프로세스도 수용해야 한다.
그리고 이 각 영역은 각각 목적에 맞도록 효율적으로 관리되어야 한다.
> 

<br/>

<br/>

> 일반적으로 여러 사용자 프로세스가 동시에 메모리에 상주하기를 원한다.
> 
- 따라서 메모리에 적재되기를 기다리는 프로세스에 사용 가능한 메모리를 할당하는 방법을 고려해야 한다.
    - **연속적인 메모리 할당**에서 각 프로세스는 다음 프로세스가 적재된 영역과 인접한 하나의 메모리 영역에 적재된다.
    - 그러나 이 메모리 할당 기법에 대해 더 논의하기 전에 메모리 보호 문제를 해결해야 한다.

<br/>

<br/>

## 메모리 보호


<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/hardware-support.png" width = 500/>


> 위 그림처럼 프로세스가 자신이 소유하지 않은 메모리를 접근할 수 없게 강제할 수 있다.
> 
- 재배치 레지스터는 가장 작은 물리 주소의 값을 저장하고, 상한 레지스터는 논리 주소의 범위값을 저장한다.
- MMU는 동적으로 논리 주소에 재배치 레지스터의 값을 더함으로써 주소를 변환한다.
    
    → 이렇게 변환된 주소는 메모리로 보내진다.
    
<br/>

<br/>


> CPU 스케줄러가 다음으로 수행할 프로세스를 선택할 때
> 
- 디스패처는 문맥 교환의 일환으로 재배치 레지스터와 상한 레지스터에 정확한 값을 적재한다.
- CPU에 의해 생성된 모든 주소는 이 레지스터들의 값을 참조해서 확인 작업을 거친다.

<br/>

<br/>

## 메모리 할당

> 메모리를 할당하는 가장 간단한 방법중 하나는 프로세스를 메모리의 가변 크기 파티션에 할당하는 것이다.
> 
- 각 파티션에는 정확히 하나의 프로세스만 적재될 수 있다.
- 이 가변 파티션 기법에서 운영체제엔 사용 가능한 메모리 부분과 사용중인 부분을 나타내는 테이블이 있다.

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/variable-partition.png" width = 500/>


<br/>

<br/>

- 처음엔 모두 사용자 프로세스에 사용 가능하며, 하나의 큰 사용 가능한 메모리 블록인 **hole**로 간주한다.

<br/>

<br/>

> 프로세스가 시스템에 들어왔을 때
> 
- OS는 각 프로세스가 메모리를 얼마나 요구하며, 또 사용 가능한 메모리 공간이 어디에 얼마나 있는지를 고려하여 공간을 할당한다.

<br/>

<br/>

> 프로세스가 공간을 할당 받았을 때
> 
- 우선 CPU를 할당받기 위해 경쟁한다.
- 프로세스가 끝내면 메모리를 반납하고, 운영체제는 다른 프로세스에 이 공간을 할당할 수 있다.

<br/>

<br/>

> 여기서 **동적 메모리 할당 문제**의 특별한 예시가 나온다.
> 
- 이것은 일련의 가용공간-리스트로부터 크기 n-바이트 블록을 요구하는 것을 어떻게 만족시켜 줄 것이냐를 결정하는 문제이다.
- 이러한 문제에 대한 해결책은 여러 개가 제시되어 있다.

<br/>

<br/>

> 가장 일반적인 기법들
> 
- **최초 적합(first-fit)**
    - 첫번째 사용 가능한 가용 공간을 할당한다.

- **최적 적합(best-fit)**
    - 사용 가능한 공간 중에서 가장 작은 것을 택한다.
    - 리스트가 크기 순으로 정렬되어 있지 않다면 전 리스트를 검색해야만 한다.

- **최악 적합(worst-fit)**
    - 가장 큰 가용 공간을 택한다.
    - 이 방식에서 할당해 주고 남게 되는 가용 공간은 충분히 커서 다른 프로세스들을 위해 유용하게 사용될 수 있다.

<br/>

<br/>

## 단편화

> 최초 적합 전략과 최적 적합 전략 모두 **외부 단편화**로 인해 어려움을 겪는다.
> 
- 프로세스들이  메모리에 적재되고 제거되는 일이 반복되면, 가용 공간은 아주 작은 공간이 되어버린다.
- ***외부 단편화는 이처럼 유휴 공간들을 모두 합치면 충분한 공간이 되지만, 그것들이 너무 작은 조각들로 여러 곳에 분산되어 있을 때 발생한다.***

<br/>

<br/>

> 메모리의 전체 크기와 프로세스 크기들은 모두 외부 단편화에 따라 큰 영향을 미칠 수 있다.
> 
- ex) 최초 적합의 경우 통계적인 부분을 분석해 보면 N개의 블록이 할당되었을 때 0.5N개의 블록이 단편화로 인해 손실될 수 있다는 것을 알 수 있다.
    - 이 현상은 **50% 규칙**이라고 알려져 있다.

<br/>

<br/>

> 메모리 공간을 낭비하는 현상인 단편화는 내부적으로도 발생할 수 있다.
> 
- 일반적으로는 메모리를 먼저 아주 작은 공간들로 분할하고, 프로세스가 요청하면 할당을 항상 이 분할된 크그의 정수배로만 할당하는 것이 보통이다.
    - 이 경우, 할당된 공간은 요구된 공간보다 약간더 크다.
    - 이들 두 크기 사이의 남는 부분이 바로 **내부 단편화**이다.

<br/>

<br/>

> 외부 단편화를 해결하는 방법 → **압축(compaction)**
> 
- 이 방법은 메모리 모든 내용을 한군데로 몰고 모든 가용 공간을 다른 한군데로 몰아서 큰 블록을 만든다.
    - 그러나 압축이 항상 가능한 것은 아님을 알고 있자!

<br/>

<br/>

> 외부 단편화를 해결하는 다른 방법
> 
- 한 프로세스의 논리 주소 공간을 여러 개의 비연속적인 공간으로 나누어 필요한 크기의 공간이 가용해지는 경우 물리 메모리를 프로세스에 할당하는 방법이다.
    - 이는 **페이징**에서 사용되는 방법으로, 아래에서 보자

<br/>

<br/>

# 💡 페이징 _Paging

> 위에서 논의된 메모리 관리는 프로세스의 물리 주소 공간이 연속적이어야 했다.
이번에 소개할 **페이징은 프로세스의 물리 주소 공간이 연속되지 않아도 되는 기법**이다.
> 

<br/>

<br/>

## 기본 방법

> 물리 메모리는 **프레임**(frame)이라 불리는 같은 크기 블록으로 나누어진다.
논리 메모리는 **페이지**(page)라 불리는 같은 크기의 블록으로 나누어진다.
> 

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/paging1.png" width = 500/>


> CPU에서 나오는 모든 주소는 **페이지 번호**(p)와 **페이지 오프셋**(d: offset)으로 나누어진다.
> 
- 페이지 번호는 프로세스 페이지 테이블(Page table)을 액세스할 때 사용된다.
- 페이지 테이블은 물리 메모리의 각 프레임의 시작 주소를 저장하고 있으며, 오프셋은 참조되는 프레임 안에서의 위치이다.

<br/>

<br/>

> 논리 주소를 물리 주소로 변환하기 위해 MMU가 취한 단계를 요약한 것
> 
1. 페이지 번호 p를 추출해 페이지 테이블의 인덱스로 사용한다.
2. 페이지 테이블에서 해당 프레임 번호 f를 추출한다.
3. 논리 주소의 페이지 번호 p를 프레임 번호 f로 바꾼다.

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/paging2.png" width = 500/>

> *페이징 자체는 일종의 동적 재배치라는 것을 알 수 있다!*
> 
- 모든 논리 주소는 페이징 하드웨어에 의해 실제 주소로 바인딩된다.
- 페이징을 사용하는 것은 각 메모리 프레임마다 하나씩 기준 레지스터를 테이블로 유지하는 것과 비슷!

<br/>

<br/>

> **페이징 기법을 사용하면 외부 단편화가 발생하지 않는다.**
> 
- 이는 모든 놀고 있는 프레임이 프로세스에 할당될 수 있기 때문이다.
    - ***하지만 내부 단편화는 여전히 발생한다.***
    - 할당은 항상 프레임의 정수배로 할당되기 때문이다.
    - 만약 프로세스가 페이지 경계와 일치하지 않는 크기의 메모리를 요구한다면?
        - → 마지막 페이지 프레임은 전부 할당되지 않는다.

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/paging3.png" width = 500/>

> 프로세스의 크기가 페이지 크기와 무관하다면, 평균적으로 프로세스당 반 페이지 정도의 내부 단편화가 예상된다.
> 
- 이런 측면에서는 작은 페이지 크기가 바람직하다는 것을 알 수 있다.
    - but, 페이지 크기가 작아지면?
    - → 반비례로 페이지 테이블의 크기가 커지게 되고, 이 테이블이 차지하는 공간은 낭비!

<br/>

<br/>

> **페이징의 가장 중요한 특징 : *메모리에 대한 프로그래머의 인식과 실제 내용이 다르다는 것!***
> 
- 프로그래머는 메모리가 하나의 연속적인 공간이며, 메모리에는 프로그램만 있다고 생각.
- 실제론 여러 곳에 프레임 단위로 분산되어 있고, 많은 다른 프로그램들도 올라와있다.

<br/>

<br/>

> 프로그래머가 생각하는 메모리와 실제 물리 메모리의 차이는 주소 변환 하드웨어에 의해 해소된다.
> 
- 논리 주소는 물리 주소로 변환한다.
    - 이 사상은 프로그래머에게는 안 보이고 운영체제에 의해 조정된다.
    - 따라서 사용자 프로세스는 자기의 것이 아닌 메모리는 접근조차 할 수가 없다.

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/paging4.png" width = 500/>

> 운영체제는 물리 메모리를 관리하기 때문에 물리 메모리의 자세한 할당에 대해 파악하고 있어야 한다.
> 
- 즉, 어느 프레임이 할당되어 있고, 어느 프레임이 사용 가능한지, 총 프레임은 몇 개나 되는지 알아야 한다.
    - 이런 정보는 일반적으로 **프레임 테이블**이라는 시스템에 하나밖에 없는 자료구조에 있다.
        - 프레임 테이블은 각 프레임당 하나의 항목을 가지고 있으며, 프레임이 비어 있는지, 할당되었는지, 그리고 할당되었다면 어느 프로세스의 어느 페이지에 할당되었는지를 나타낸다.

<br/>

<br/>

> 또한, 운영체제는 모든 프로세스의 주소들을 실제 주소로 사상할 수 있어야 한다.
> 
- 만약 사용자가 시스템 콜(system call)을 호출해 인자로 어떤 주소를 주면, 제대로 사상하여 정확히 그 물리 주소를 찾아가야 한다.

<br/>

<br/>

> 운영체제는 명령 카운터와 레지스터의 사본을 유지하는 것처럼 각 프로세스의 페이지 테이블 사본을 유지한다.
> 
- 이 사본은 운영체제가 논리 주소에 대응하는 물리 주소를 직접 사상해야 할 때마다 논리 주소를 물리 주소로 변환하는 데 사용된다.

<br/>

<br/>

## 하드웨어 지원

> 페이지 테이블의 하드웨어 구현은 여러 가지 방법으로 수행할 수 있다.
> 
- 가장 간단한 방법
    - 전용 고속 하드웨어 레지스터 세트로 구현되므로, 페이지 주소 변환에 매우 효율적이다.
    - But, 이러한 방식은 각각의 레지스터가 문맥 교환 중에 교체되어야 하므로 문맥 교환 시간을 증가시킨다.

<br/>

<br/>

> 페이지 테이블에 레지스터를 사용하는 것은 페이지 테이블이 작은 경우 적합하다.
> 
- 대부분의 컴퓨터는 페이지 테이블을 메인 메모리에 저장하고, **페이지 테이블 기준 레지스터(PTBR)**로 하여금 페이지 테이블을 가리키도록 한다.

<br/>

<br/>

### TLB: Translation Look-Aside Buffer

> 메인 메모리에 페이지 테이블을 저장하면 문맥 교환 속도는 빠르지만, 메모리 액세스 시간이 느려진다.
> 
- 또한 어떤 경우, ***두 번의 메모리 액세스가 필요***해 질 수도 있다.
    - 이 문제의 해결책으론 **TLB**가 제시된다.

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/paging5.png" width = 500/>

> TLB는 매우 빠른 연관 메모리로 구성된다.
> 
- 내부의 각 항목은 키와 값의 두 부분으로 구성된다.
- TLB에 페이지를 찾아달라고 요청이 들어오면, 찾고자 하는 페이지를 동시에 여러 개의 내부 키와 비교한다.

<br/>

<br/>

> **TLB miss : 페이지 번호가 TLB에 없는 경우**
> 
- 페이지 테이블에 대한 메모리 참조가 이루어져야 한다.
- 만약 TLB가 가득 차면? → 기존 항목 중 교체될 항목을 선택해야 한다.

<br/>

<br/>

> 어떤 TLB는 각 항목에 **ASIDs**(address-space identifiers)를 저장하기도 한다.
> 
- ASID는 그 TLB 항목이 어느 프로세스에 속한 것인지를 알려주며, 그 프로세스의 정보를 보호한다.
    - TLB에선 가장 주소를 변환할 때 현재 수행중인 프로세스의 ASID가 TLB 항목에 있는 ASID와 같은지를 검사한다.
        - ***ASID가 일치하지 않으면? → TLB miss로 처리!***

<br/>

<br/>

> 접근하려는 메모리의 페이지 번호가 TLB에서 발견되는 비율을 적중률(`hit ratio`)이라고 부른다.
> 
- 적중률 80% = TLB에서 원하는 페이지 번호를 얻을 횟수가 80%
- **실질 메모리 접근 시간**(`effective memory access time`)
    - 적중률 * 메인 메모리 접근 시간 + (1 - 적중률) * 메인 메모리 접근 시간 * 2

<br/>

<br/>

## 보호

> 페이징 환경에서 메모리 보호는 각 페이지에 붙어있는 보호 비트에 의해 구현된다.
> 
- 각 비트는 이 페이지가 읽고, 쓰기 또는 읽기 전용임을 각각 정의할 수 있다.

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/paging6.png" width = 500/>

> 페이지 테이블의 각 엔트리는 유효/무효라는 하나의 비트가 더 있다.
> 
- 유효(valid) → 그 페이지는  프로세스의 합법적인 페이지임
- 무효(invalid) → 페이지가 프로세스의 논리 주소 공간에 속하지 않음

<br/>

<br/>

## 공유 페이지

> 페이징의 장점은 공통의 코도를 ***공유***할 수 있다는 점이다.
> 

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/paging7.png" width = 500/>

> 위 그림에선 표준 C 라이브러리 libc에 대한 페이지를 공유하는 세 가지 프로세스가 있다.
> 
- 재진입 코드는 자체 수정을 할 수 없는 코드로, 실행 중에는 절대 변경되지 않는다.
    - 따라서 두 개 이상의 프로세스가 동일한 코드를 동시에 실행할 수 있다.
    - ***위 경우에는 하나의 사본만 저장이 되고, 나머지는 물리적 사본으로 매핑시켜 공간을 절약한다!***

<br/>

<br/>

# 가상 메모리
> 가상 메모리(`virtual memory`)란?
>
>→ 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법이다. 
>
>→ 주요 장점은 하나는 사용자 프로그램이 물리 메로리보다 커져도 된다는 점이다! 

<br/>

<br/>

## 💡 배경 _Background

> 실행 중인 코드는 반드시 물리 메모리에 있어야 한다는 것은 일견 필요하고 타당한 요구 조건으로 보이지만, 프로그램의 크기를 물리 메모리의 크기로 제한한다는 점 때문에 마냥 좋은 요구 조건은 아니다.
> 

<br/>

<br/>

> 실제 프로그램을 살펴보면 많은 경우에 프로그램 전체가 한꺼번에 메모리에 늘 올라와 있어야 한다는 건 아님을 쉽게 발견할 수 있다.
> 
- 프로그램에 잘 발생하지 않는 오류 상황을 처리하는 코드가 종종 존재한다.
    - 이런 오류들은 실질적으론 거의 발생하지 않는다.
- 배열, 리스트, 테이블 등은 필요 이상으로 많은 공간을 점유할 수도 있다.
- 프로그램 내의 어떤 옵션이나 기능들은 거의 사용되지 않는다.

<br/>

<br/>

> 만일 프로그램을 일부분만 메모리에 올려놓고 실행할 경우의 얻는 이점
> 
- 프로그램은 물리 메모리 크기에 의해 더는 제약받지 않게 된다.
    - → 사용자들은 매우 큰 ***가상*** 주소 공간을 가정하고 프로그램을 만들 수 있다.
- 각 프로그램이 더 작은 메모리를 차지하므로 더 많은 프로그램을 동시에 수행할 수 있게 된다.
- 프로그램을 메모리에 올리고 스왑하는데 필요한 I/O 회수가 줄어들기 때문에 프로그램 실행이 빠르다.

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-background1.png" width = 500/>


> **가상 메모리**는 실제의 물리 메모리 개념과 개발자의 논리 메모리 개념을 분리한 것이다.
> 
- 이로써 작은 메모리를 가지고도 얼만든지 큰 가상 주소 공간을 프로그래머에게 제공할 수 있다는 점이다.

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-background2.png" width = 500/>

> 한 프로세스의 **가상 주소 공간**은 그 프로세스가 메모리에 저장되는 논리적인 모습(view)을 말한다.
> 
- 일반적으로 위 그림과 같이 특정 논리 주소에서 시작하여 연속적인 공간을 차지한다.
    - 힙과 스택 사이의 공백도 가상 주소 공간의 일부이다. (**성긴 주소 공간**)

<br/>

<br/>

> 가상 메모리는 페이지 공유를 통해 프로세스들에게 (파일 또는 메모리) 공유를 제공한다.
> 
- 표준 C 라이브러리와 같은 시스템 라이브러리가 여러 프로세스들에 공유되는 것이 예시이다.
- 마찬가지로 프로세스들이 메모리를 공유할 수 있다! → 아래 사진 참고
    
    <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-background3.png" width = 500/>


<br/>

<br/>

# 💡 요구 페이징 _Demand Paging

> 어떻게 실행 프로그램을 보조저장장치에서 메모리로 적재할 수 있을까?
> 
- → 필요한 페이지만 적재하자! = ***요구 페이징(demand paging)***
    - 일반적으로 가상메모리 시스템에서 사용되며, **필요할 때**만 페이지가 적재된다.

<br/>

<br/>

## 기본 개념

> 요구 페이징의 기본 개념은 필요할 때만 페이지를 메모리에 적재하는 것이다.
> 
- 결과적으로 프로세스가 실행되는 동안 일부 페이지는 메모리에 있고 일부는 보조저장장치에 있다.
    
    <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-background4.png" width = 500/>

    

<br/>

<br/>

> 그러나 프로세스가 메모리에 올라와 있지 않은 페이지에 접근하려고 하면 어떤 일이 발생할까?
> 
- ***페이지 폴트*** 트랩 발생!
    - 페이지 테이블 항목이 무효로 설정되어 있을 때를 의미.

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-background5.png" width = 500/>


<br/>

<br/>

> 페이지 폴트를 처리하는 과정
> 
1. 프로세스에 대한 내부 테이블을 검사해서 그 메모리 참조가 유효인지 무효인지 검사
2. 만약 무효한 페이지에 대한 참조라면 그 프로세스는 중단된다.
    1. 유효한 참조인데 페이지가 아직 메모리에 올라오지 않았다면, 보조저장장치로부터 가져와야 한다.
3. 빈 공간, 즉 가용 프레임을 찾는다.
4. 보조저장장치에 새로이 할당된 프레임으로 해당 페이지를 읽어 들이도록 요청한다.
5. 보조저장장치 읽기가 끝나면, 이 페이지가 이제는 메모리에 있다는 것을 알리기 위해 페이지 테이블을 갱신하며, 프로세스가 유지하고 있는 내부 테이블을 수정한다.
6. 트랩에 의해 중단되었던 명령어를 다시 수행한다.

<br/>

<br/>

> 극단적인 경우: 메모리에 페이지가 ***하나도*** 안 올라와있는 상태에서도 프로세스를 실행할 수 있음!
> 
- OS에서 명령 포인터의 값을 프로세스의 첫 명령으로 설정하는 순간?
    - → 이 명령이 메모리에 존재하지 않는 페이지에 있으므로, 페이지 폴트를 발생!
- 페이지가 적재되고 나면 프로세스는 수행을 계속하는데, 페이지를 필요할 때마다 폴트가 발생
    - 일단 필요한 모든 페이지가 적재되고 나면 더 폴트가 발생하지는 않는다.
    - 이것이 순수 요구 페이징(`pure demand paging`)이다.

<br/>

<br/>

> 프로그램들은 한 명령어에서도 여러 개의 페이지 폴트를 일으킬 수 있다.
> 
- 다행히 실행중인 프로세스들을 분석해보면 이러한 경우는 거의 발생하지 않는다.
    - 모든 프로그램은 **참조의 지역성**이라는 성질이 있어 어느 한 특정 작은 부분만 한동안 집중적으로 참조하는데, 이러한 성질 덕에 요구 페이징은 만족할 만한 성능을 보인다.

<br/>

<br/>

> 요구 페이징을 지원하기 위해 필요한 하드웨어는 페이지오가 스와핑을 위한 하드웨어와 동일하다.
> 
- 페이지 테이블 : 보호 비트들 특별한 값 또는 유효/무효 비트를 통해 특정 항목을 무효로 설정할 수 있다.
- 보조저장장치 : 메인 메모리에 없는 모든 페이지를 가지고 있다.
    - 보통 고성능 디스크 또는 NVM 장치로, 스왑 장치라고도 한다.
    - 이 목적을 위해 사용되는 저장장치 영역을 **스왑 공간**이라고 한다

<br/>

<br/>

> 한 명령어가 많은 기억 장소를 변경하는 것일 때에는 상당히 어려운 문제가 발생한다.
> 
- 이러한 문제는 두 가지 해결법이 있다.
    1. 마이크로코드로 양 블록의 두 끝을 계산해 겹치지 않는 것을 확인하기
        1. 만약 페이지 폴트가 발생할 가능성이 있다면 미리 페이지 폴트를 발생시킨다.
        2. 그 후에 이동을 시작하면 어떤 페이지 폴트도 일어날 수 없다.
    2. 이동에 의해서 이전의 내용이 지워질 기억 장소드의 값을 보존하기 위해 임시 레지스터들을 사용하기
        1. 복구의 용도로 사용

<br/>

<br/>

## 가용 프레임 리스트

> 페이지 폴트가 발생하면 운영체제는 요청된 페이지를 보조저장장치에서 메인 메모리로 가져와야 한다.
OS는 페이지 폴트를 해결하기 위해 가용 프레임의 풀인 **가용 프레임 리스트**를 유지한다.
> 
- 프로세스의 스택 또는 힙 세그먼트가 확장될 때도 가용 프레임이 할당 되어야 한다!
    - OS는 일반적으로 **zero-fill-on-demand**라는 기법을 사용!
        
        <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-background6.png" width = 500/>

        
    - 여기서 `Zero-fill-on-demand` 프레임은 할당되기 전에 0으로 모두 채워져 이전 내용이 지워진다.

<br/>

<br/>

## 요구 페이징의 성능

> 요구 페이징은 컴퓨터 시스템의 성능에 큰 영향을 줄 수 있다.
> 

→ 요구 페이지 메모리에 대한 **실질 접근 시간**을 계산해보자.

<br/>

<br/>

> 페이지 폴트의 확률 p(0 ≤ p ≤1)
> 
- 실질 접근 시간 = (1-p) * ma + p * 페이지 폴트 시간

<br/>

<br/>

> 페이지 폴트의 처리 순서
> 
1. 운영체제에 트랩을 요청
2. 레지스터들과 프로세스 상태를 저장
3. 인터럽트 원인이 페이지 폴트임을 알아냄
4. 페이지 참조가 유효한 것인지 확인하고, 보조저장장치에 있는 페이지의 위치를 알아냄.
5. 저장장치에 가용 프레임으로의 읽기 요구를 냄
    1. 읽기 차례가 돌아오기까지 대기 큐에서 기다린다.
    2. 디스크에서 찾는 시간과 회전 지연 시간 동안 기다린다.
    3. 가용 프레임으로 페이지 전송을 시작한다.
6. 기다리는 동안 CPU 코어는 다른 사용자에게 할당
7. 저장장치가 다 읽었다고 인터럽트를 검
8. 다른 프로세스의 레지스터들과 프로세스 상태를 저장
9. 인터럽트가 보조저장장치로부터 왔다는 것을 알아냄
10. 새 페이지가 메모리로 올라왔다는 것을 페이지 테이블과 다른 테이블들에 기록
11. CPU 코어가 자기 차례로 오기까지 다시 기다림
12. CPU 차례가 오면 위에서 저장시켜 두었던 레지스터들, 프로세스 상태, 새로운 페이지 테이블을 복원시키고 인터럽트 되었던 명령어를 다시 실행

<br/>

<br/>

> 어떤 경우에도, 페이지 폴트 처리 시간은 다음 3개의 주요 작업 요소로 이루어져 있음을 알 수 있다.
> 
1. 인터럽트의 처리
2. 페이지 읽기
3. 프로세스 재시작

<br/>

<br/>

> 실질 접근 시간 구하기 예시
> 
- 평균 페이지 폴트 처리 시간이 8밀리초이고, 메모리 접근 시간이 200나노초 임을 가정
- 실질 접근 시간 = (1-p) * 200 + p * (8milliseconds)
= (1-p) * 200 + p * 8,000,000 = 200 + 7,999,800 * p

<br/>

<br/>

**→ 실제 접근 시간은 페이지 폴트율에 비례한다!**

> 요구 페이징의 또 다른 특성 중 하나는 스왑 공간의 관리이다.
> 
- 스왑 공간에서의 디스크 I/O은 일반적으로 파일 시스템에서의 입출력보다 빠르다.
    - → 스왑 공간은 파일 시스템보다 더 큰 블록을 사용하기 때문!
    - 또 스왑 공간과 입출력을 할 때는 파일 찾기나 간접 할당 방법 등을 사용하지 않기 때문!

<br/>

<br/>

> 어떤 시스템들은 실행 파일을 스왑 공간에 넣지 않음으로써 스왑 공간의 크기를 줄이기도 한다.
> 
- 실행 파일로부터 요구 페이지를 요청하면 파일 시스템으로부터의 그 페이지를 직접 가져온다.
- 이 페이지들의 교체가 필요하면 이들 페이지에 새 페이지의 내용을 덮어쓸 수 있다.
- 페이지가 다시 필요해지면 추후 파일 시스템으로부터 다시 읽어 들일 수 있다.
    - → 이러한 방식에선 파일 시스템이 백업 저장장치로 사용됨!
    - 그러나 스왑 공간은 여전히 파일과 관련이 없는 페이지 때문에 필요하다.
        - → 이러한 메모리를 **익명(anonymous) 메모리**라고 한다.


<br/>

<br/>

# 💡 쓰기 시 복사 _Copy-on-Write

> `fork()` 시스템콜은 부모 프로세스와 똑같은 자식 프로세스를 만들어 주는 것임을 상기하라.
> 
- 과거엔 `fork()` 를 하면 부모 프로세스의 페이지들을 실제로 자식에 복사 → 자식의 주소 공간을 구성!
    - 하지만 대부분의 자식은 이렇게 만들어지자마자 `exec()` 시스템 콜을 한다.
    - → 이러면 부모로부터 복사해온 페이지들이 다 쓸데없어짐!
    - 그래서 부모의 페이지들을 복사해오는 대신 **쓰기 시 복사 방식**을 사용할 수 있다!

<br/>

<br/>

> 쓰기 시 복사는 자식 프로세스가 시작할 때 부모의 페이지를 당분간 함께 사용하도록 한다.
> 
- 이때 공유되는 페이지를 쓰기 시 복사 페이지라고 표시한다.
- ***둘 중 한 프로세스가 공유중인 페이지에 쓸 때 그 페이지의 복사본이 만들어진다는 의미!***

<br/>

<br/>

- 공유 페이지 사용 전
    
    <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-7.png" width = 500/>

<br/>

<br/>

    
- 공유 페이지 사용 후
    
    <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-8.png" width = 500/>

<br/>

<br/>

# 💡 페이지 교체 _Page Replacement

> 다중 프로그래밍 정도를 더 올리면, **메모리 과할당**(`over-allocating`)이 발생한다.
> 
- 10개의 페이지 중 5개만을 사용하는 6개의 프로세스를 실행시키면?
    - → 10개의 프레임은 남겨놓고도 높은 CPU 활용률과 처리율을 얻을 수 있다.
    - 그러나 특정 데이터 조합에 대해 이 프로세스들이 10페이지 모두를 사용해야 하는 상황이 발생할 수 있고, 이러면 40프레임만이 존재하는 상황에서 60프레임을 필요로 하게 된다.

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-9.png" width = 500/>

> 얼마만큼의 메모리를 I/O 용도로 할당하고, 얼마만큼을 프로그램에 할당하는가는 매우 중요하다.
> 
- 메모리의 초과 할당은 다음과 같이 나타난다.
    - 프로세스가 실행되는 동안 페이지 폴트 발생
    - OS는 필요로 하는 페이지가 보조저장장치에 저장된 위치를 알아내지만,
    가용한 프레임 목록에 ***가용한 프레임이 없음***을 발견
        - → 즉, 모든 메모리가 사용중!

<br/>

<br/>

- 이 시점에서 OS는 몇 가지 선택을 할 수 있다.
    1. 프로세스를 종료할 수 있다.
        1. 단, 요구 페이징은 시스템의 활용률과 처리율을 올리기 위해 운영체제가 선택한 방법이다.
        2. 사용자가 그들의 프로세스가 페이징 시스템에서 실행되고 있음을 알게 해선 안된다.
        3. 따라서 좋은 방법이 아님!
    2. 표준 스와핑을 사용해 프로세스를 스왑아웃하여 모든 프레임을 비우고 다중 프로그래밍 정도를 줄인다.
        1. 대부분의 운영체제는 **페이징 스와핑과 페이지 교체를 결합**한다.

<br/>

<br/>

## 기본적인 페이지 교체

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-10.png" width = 500/>

> 페이지 폴트 서비스 루틴이 페이지 교체를 포함해 아래와 같이 수정되어야 한다.
> 
1. 보조저장장치에서 필요한 페이지의 위치를 알아낸다.
2. 빈 페이지 프레임을 찾는다.
    1. 비어 있는 프레임이 있다면 그것을 사용한다.
    2. 비어 있는 프레임이 없담녀 **희생될(victim) 프레임**을 선정하기 위해 페이지 교체 알고리즘을 가동
    3. 희생될 페이지를 보조저장장치에 기록, 관련 테이블을 수정
3. 빼앗은 프레임에 새 페이지를 읽어오고 테이블을 수정한다.
4. 페이지 폴트가 발생한 지점에서부터 프로세스를 계속한다.

<br/>

<br/>

> ***빈 프레임이 없는 경우엔 디스크를 두 번 접근해야 한다는 사실에 주의하자!***
> 
- 이러한 오버헤드는 **변경 비트**를 사용해 감소시킬 수 있다.
    - 각 페이지나 프레임은 그걳과 관련된 변경 비트를 하드웨어에 가지게 된다.
    - 변경 비트는 어떤 바이트라도 내용을 쓰면 페이지가 변경되었음을 나타낸다.

<br/>

<br/>

> 페이지 교체는 요구 페이징의 기본이다.
> 
- 이를 통해 논리적 메모리와 물리 메모리 간의 분리가 완성된다.
- 이 기법을 통해 매우 작은 물리 메모리로도 프로그래머에게 광대한 가상 메모리를 제공할 수 있다!

<br/>

<br/>

> 요구 페이징 시스템은 중요한 두 가지 문제를 해결해야 한다.
> 
1. 프레임 할당 알고리즘
2. 페이지 교체 알고리즘
    
    → 즉, 여러 프로세스가 존재하는 경우 각 프로세스에 얼마나 많은 프레임을 할당해야 할지 결정
    
    → 또한 페이지 교체가 필요할 때마다 어떤 페이지를 교체해야 할 지 결정해야 한다.
    

<br/>

<br/>

> 페이지 교체 알고리즘의 성능 평가
> 
- 특정 메모리 참조 나열에 대해 알고리즘을 적용하여, 페이지 폴트 발생 횟수를 계산해 평가한다.
    - → 이러한 메모리 주소의 나열을 참조열이라 부른다.
    - → 참조열은 인공적으로 생성할 수도 있고, 주어진 시스템을 추적하여 매 메모리 참조 시의 주소를 기록할 수도 있다.

<br/>

<br/>

## FIFO 페이지 교체

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-11.png" width = 500/>

> 가장 간단한 알고리즘으로, 페이지를 교체해야 할 때 메모리에 올라온 지 가장 오래된 페이지를 내쫓는다.
> 
- 페이지가 올라온 시간을 페이지마다 기록해도 되고, 큐를 만들어 가지고 있어도 된다.

<br/>

<br/>

> FIFO 페이지 교체 알고리즘은 이해하기도 쉽고, 프로그래밍하기도 쉽다!
> 
- 그러나 성능이 항상 좋지는 않다.
    - 교체된 페이지가 오래전 사용된 뒤 더는 사용되지 않았던 초기화 모듈일 수도 있고,
    - 반대로 교체된 페이지가 초기화된 뒤 계속 자주 사용되는 변수를 포함하고 있을 수도 있다!

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-12.png" width = 500/>

> 페이지 폴트율 대 할당된 프레임 수 간의 그래프
> 
- 그래프를 보면 **Belady의 모순(Belady’s anomaly)**이 일어난 것을 볼 수 있다.
    - 이는 프로세스에 **프레임을 더 주었는데 오히려 페이지 폴트율은 더 증가하는 현상**을 말한다.

<br/>

<br/>

## 최적 페이지 교체

> Belady의 모순이 가져온 결과 중 하나는 **최적 교체 정책**에 대한 탐색이다.
> 
- 최적 교체 정책이란 모든 알고리즘보다 낮은 페이지 폴트율을 보이며 Belady의 모순이 발생하지 않는다!
    - OPT 또는 MIN으로 불린다.
    - 이를 요약하면 **“ 앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체하라. “** 이다.
        
        <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-13.png" width = 500/>
        

<br/>

<br/>

> ***안타깝게도 이 알고리즘의 실제 구현은 어렵다.***
> 
> 
> ***→ 프로세스가 앞으로 메모리를 어떻게 참조할 것인지를 미리 알아야 하기 때문!***
> 

<br/>

<br/>

## LRU 페이지 교체

> 최적 알고리즘의 근사 알고리즘
> 
- FIFO와 OPT 알고리즘의 결정적인 차이
    - FIFO : 알고리즘이 페이지가 메모리로 들어온 시간을 이용
    - OPT : 페이지가 ***사용될*** 시간을 이용

→ 최근의 과거를 가까운 미래의 근사치로 본다면, ***가장 오랜 기간 동안 사용되지 않은 페이지를 교체***하자!

= `Least-recently-used(LRU)` 알고리즘

<br/>

<br/>

> LRU 알고리즘은 페이지마다 마지막 사용 시간을 유지한다.
> 
- 페이지 교체 시에 LRU는 가장 오랫동안 사용되지 않은 페이지를 선택한다.
- 이 정책은 미래 대신 과거 시간에 대해 적용한 최적 교체 정책으로 생각할 수 있다.

<br/>

<br/>

> LRU 정책은 페이지 교체 알고리즘으로 자주 사용되며 좋은 알고리즘으로 인정받고 있다.
> 
- 문제는 ***어떻게*** 이 알고리즘을 구현하느냐 하는 것이다.
    - 이 알고리즘은 하드웨어의 지원이 필요하다!
    - 프레임들을 최근 사용된 시간 순서로 파악할 수 있어야 하는 것이다.

<br/>

<br/>

> 두 가지 구현 방법
> 
- 계수기(`counter` ) :
    - 가장 간단한 방법으로, 각 페이지 항목마다 사용 시간 필드를 넣고 CPU에 논리적인 시계나 계수기를 추가한다.
    - 메모리가 접근될 때마다 시간은 증가한다.
    - 페이지에 대한 참조가 일어날 때마다 페이지의 사용 시간 필드에 시간 레지스터의 내용이 복사된다.

<br/>

<br/>

- 스택(`stack` ) :
    - LFU 교체 정책의 다른 구현 방법은 페이지 번호의 스택을 유지하는 방법이다.
    - 페이지가 참조될 때마다 페이지 번호는 스택의 중간에서 제거되어 꼭대기(top)에 놓이게 된다.

<br/>

<br/>

> 최적 교체와 마찬가지로 LRU는 Belady의 모순 현상을 야기하지 않는다.
> 
- 페이지 교체 알고리즘 중에는 Belady의 모순 현상을 나타내지 않는 것들이 있다.
    - 이러한 알고리즘들을 **스택 알고리즘**이라고 부른다.

<br/>

<br/>

> 양쪽 LRU 구현 방법 모두 반드시 표준적인 TLB 레지스터 이상의 하드웨어 지원이 있어야 한다.
> 
- 계수기 값과 스택을 갱신하는 일을 메모리 참조 때마다 수행되어야 한다.

<br/>

<br/>

## LRU 근사 페이지 교체

> LRU 페이지 교체 지원을 충분히 할 수 있는 하드웨어는 많지 않다.
어떤 시스템에서는 전혀 하드웨어적인 지원을 하지 않고 다른 알고리즘을 쓸 수 밖에 없다.
> 
- → 그러나 많은 시스템은 **참조 비트**의 형태로 어느 정도 지원은 하고 있다!

<br/>

<br/>

### 부가적 참조 비트 알고리즘

> 일정한 간격마다 참조 비트들을 기록함으로써 추가적인 선후 관계 정보를 얻을 수 있다.
> 

<br/>

<br/>

- 동작 방식
    - 각 페이지에 대해 8비트의 참조 비트를 할당한다.
    - 일정한 시간 간격마다, 타이머 인터럽트를 걸어 운영체제가 참조 비트를 8비트 정보의 최상위 비트로 이동시키고, 나머지 비트들은 하나씩 오른쪽으로 이동시킨다.
        - 이 8비트 값을 정수로 생각한다면 가장 작은 수를 갖는 페이지가 LRU 페이지이고, 교체할 수  있다

<br/>

<br/>

- 물론 사용하는 비트 수는 달라질 수 있고, 갱신을 가능한 가장 빠르게 하기 위한 크기가 선택된다.
    - 극단적인 경우 0이 될 수 있고, 이 경우는 참조 비트만이 남게 된다.
    - 이 알고리즘을 **2차 기회 알고리즘**이라 부른다.

<br/>

<br/>

### 2차 기회 알고리즘

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-14.png" width = 500/>

> 2차 기회 알고리즘의 기본은 FIFO 교체 알고리즘이다.
> 
- 그러나 페이지가 선택될 때마다 참조 비트를 확인한다.
    - 참조 비트가 0이면 → 페이지를 교체
    - 참조 비트가 1이면 → 다시 한번 기회를 주고 다음 FIFO 페이지로 넘어간다.
        - 한번 기회를 받게 되면 참조 비트는 해제되고 도착 시간이 현재 시각으로 재설정된다.

<br/>

<br/>

- 이에 따라 그 페이지는 다른 모든 페이지가 교체될 때까지 교체되지 않는다.
    - 따라서, 참조 비트가 계속 설정되어 있을 정도로 자주 사용되는 페이지는 전혀 교체되지 않을 것이다.

<br/>

<br/>

> 2차 기회 알고리즘을 구현하는 하나의 방법은 순환 큐를 이용하는 것이다.
> 
- 이 큐에는 포인터가 있어 다음에 교체될 페이지를 가리킨다.
    - 최악의 경우, 모든 비트가 1값을 가지고 있었으면 포인터는 큐를 완전히 한바퀴 돈다.
    - 그러고 나면 모든 페이지는 기회가 주어지게 된다.
        - 두 번째 돌 때는 사실상 FIFO와 같은 것이 된다.

<br/>

<br/>

### 개선된 2차 기회 알고리즘

> 참조 비트와 변경 비트를 사용해 더 개선할 수 있다.
> 
- 이 두 개의 비트를 조합해 사용하면 네 가지의 등급이 가능하다!
    - (0, 0) : 최근의 사용되지도 변경되지도 않은 경우 → 교체하기 가장 좋은 페이지
    - (0, 1) : 최근에 사용되지는 않았지만 변경은 됨 → 이 페이지는 뺏어 오려면 디스크에 내용을 기록해야 함
    - (1, 0) : 최근에 사용은 되었으나 변경은 되지 않은 경우 → 이 페이지는 곧 다시 사용될 가능성이 높음
    - (1, 1) : 최근에 사용도 되었고 변경도 된 경우 → 아마 곧 다시 사용될 것이며 뺏으려면 역시 디스크에 그 내용을 먼저 기록해야 함.

<br/>

<br/>

## 계수-기반 페이지 교체

> 페이지 교체를 위해 사용되는 많은 다른 알고리즘이 있다.
> 
<br/>

<br/>

- **LRU 알고리즘**
    - 참조 횟수가 가장 적은 페이지를 교체하는 방법이다.
    - 어떤 프로세스가 그 초기 단계에서는 한 페이지를 집중적으로 많이 사용하지만 그 후로 다시는 이 페이지를 사용하지 않는 경우에 판단이 빗나갈 수 있다.
    - 한 가지 해결책
        - 참조 횟수를 일정한 시간마다 하나씩 오른쪽으로 시프트해서 지수적으로 그 영향력을 줄이기!

<br/>

<br/>

- **MFU 알고리즘 (Most Frequently Used)**
    - 가장 작은 참조 횟수를 가진 페이지가 가장 최근 참조된 것이고 앞으로 사용될 것이라는 판단에 근거
    - 일반적으로 잘 쓰이지 않는다.
        - 구현 비용이 많이 들고, OPT에 근사하지도 않기 때문

<br/>

<br/>

## 페이지-버퍼링 알고리즘

> 페이지 교체 알고리즘과 병행해 여러 가지 버퍼링 기법이 사용될 수 있다.
> 
<br/>

<br/>

- 시스템이 가용 프레임 여러 개를 풀로 가지고 있다가, 페이지 폴트가 발생하면 예전과 마찬가지로 교체될 페이지를 찾지만, 교체될 페이지의 내용을 디스크에 기록하기 전에 가용 프레임에 새로운 페이지를 먼저 읽어 들이는 방법이다.
    - 위 방법의 확장 → 변경된 페이지 리스트를 유지하는 방법도 있다.
        - 페이징 장치가 아무런 일도 없게 되면 그때마다 변경된 페이지들을 차례로 보조저장장치에 쓴 후에, 페이지의 변경 비트를 0으로 되돌려 놓는다.

<br/>

<br/>

- 다른 방법은 가용 프레임 풀을 유지하지만 그 풀 속 프레임의 원래 임자 페이지가 누구였었는지 기록하기!
    - 풀 속의 프레임 내용은 그것을 보조저장장치에 썼다고 하더라도 수정되지 않았을 확률이 있다.

<br/>

<br/>

## 응용(application)과 페이지 교체

> 몇몇 경우에는 운영체제의 가상 메모리를 통해 데이터에 접근하는 응용이 운영체제가 전혀 버퍼링 기능을 제공하지 않는 경우에 비해 오히려 안 좋은 성능을 보일 때가 있다.
> 

<br/>

<br/>

- 이러한 문제들 때문에, 몇몇 운영체제는 특별한 프로그램들에는 보조저장장치 파티션을 파일 시스템 구조가 아닌 단순한 논리적인 블록들의 순차적인 배열로써 사용할 수 있게 해주는 기능을 갖춘다.
    - 이 배열은 종종 **raw disk**라고 불린다.
    - 특정 응용들이 raw 파티션을 이용해 자신만의 특수한 저장장치 서비스를 구현하는 것이 효율적인 데 비해 대부분의 응용은 정상적인 파일 시스템 서비스를 이용해 동작하는 것이 더 좋은 성능을 보임을 알자.


<br/>

<br/>

# 💡 프레임의 할당 _Allocation of Frames

> 메모리 할당에는 다양한 제한이 존재한다.
> 
> - ex) 가용 프레임 수보다 더 많이 할당할 수는 없다, 또한 최소한  몇 페이지는 할당해야 한다 등등

<br/>

<br/>

## 최소로 할당해야 할 프레임의 수

> 최소한의 프레임은 할당해야만 하는 한 가지 이유는 성능과 관계된다.
> 
- 각 프로세스에 할당되는 프레임 수가 줄어들면 페이지 폴트율은 증가하고 프로세스 실행은 늦어진다.
- 또한, 명령어 수행이 완료되기 전에 페이지 폴트가 발생하면 그 명령어를 재실행되어야 한다.
    - 따라서 하나의 명령어가 참조하는 모든 페이지는 동시에 메모리에 올라와 있어야 수행이 끝난다!

<br/>

<br/>

> 최소 프레임 수는 컴퓨터 아키텍처에 의해 정의된다.
> 
- 프로세스당 최소 프레임 수는 아키텍처에 의해 정의되는 반면, 최대 수는 사용 가느안 물리 메모리 양에 의해 정의된다.
    - → 이 둘 사이에 여전히 프레임 할당에서 중요한 선택을 해야 한다!

<br/>

<br/>

## 할당 알고리즘

> 가장 쉬운 방법
> 
- n개의 프로세스에 m개의 프레임을 분할한다. (m/n)
    - 이때, 현재 운영체제가 사용해야 하는 프레임은 제외된다.
    - 이러한 방법을 **균등 할당(equal allocation)**이라 한다.

<br/>

<br/>

> 또 다른 대안은 프로세스마다 그 크기가 다르다는 점을 고려한 것이다.
> 
- 가용 메모리를 각 프로세스의 크기 비율에 맞추어 할당하는 방법인 **비례 할당** 방식이 있다.
    - 이처럼, 프로세스는 균등성보다는 각자의 ***요구량***에 기반하여 가용 프레임을 공유할 수 있다.

<br/>

<br/>

> 두 방법 모두 다중 프로그래밍 정도에 따라 할당되는 양이 달라진다.
***여기서 중요한건 둘 다 모두 높은 우선순위의 프로세스와 낮은 우선순위를 동등하게 취급한다는 것!***
> 

<br/>

<br/>

## 전역 대 지역 할당

> 다수의 프로세스가 할당을 위해 경쟁하는 환경에서 페이지 교체 알고리즘은 크게 두 가지 범주가 있다.
> 
- 전역 교체(global replacement)
    - 프로세스가 교체할 프레임을 다른 프로세스에 속한 프레임을 포함한 모든 프레임을 대상으로 찾기
- 지역 교체(local replacement)
    - 각 프로세스가 자기에게 할당된 프레임 중에서만 교체될 희생자를 선택할 수 있는 경우

<br/>

<br/>

> 우선순위가 높은 프로세스가 낮은 프로세스의 프레임 중 뺏어올 수 있는 할당 기법을 생각해보자.
> 
- 지역 교체 : 프로세스에 할당된 프레임 수는 변하지 않는다.
- 전역 교체 : 프로세스가 매번 다른 프로세스의 프레임을 할당받으면 → 프레임에 할당된 페이지 수가 증가!

<br/>

<br/>

> 전역 교체 알고리즘의 한 가지 문제점
> 
- 프로세스의 메모리에 있는 페이지 집합이 해당 프로세스의 페이징 동작뿐만 아니라 다른 프로세스의 페이징 동작에도 영향을 받는다!
    - → 따라서 프로세스도 그때그때 외부적 환경에 따라서 전혀 다르게 실행될 수 있다.

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-15.png" width = 500/>

> 이 전략은 전역 페이지 교체 정책을 구현하는 데 사용할 수 있는 전략 중 하나다.
> 
- 전략의 목적은 가용 메모리 양을 최소 임계 값 이상으로 유지하는 것이다.
    - 이 임계값 아래로 떨어지면 → 시스템의 모든 프로세스에서 페이지를 회수하기 시작하는 커널 루틴이 촉발된다.
    - 이러한 커널 루틴은 종종 **리퍼(reaper)**라고 알려져 있으며, 모든 페이지 교체 알고리즘을 적용할 수 있다.

<br/>

<br/>

## 비균등 메모리 접근

> 여러 개의 CPU를 가진 **비균등 메모리 접근(NUMA)** 시스템에선 특정 CPU는 메인 메모리의 일정 영역을 다른 영역보다 빠르게 접근할 수 있다.
> 

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-16.png" width = 500/>

> 어느 페이지를 어느 프레임에 할당하느냐 하는 정책이 NUMA 성능에 커다란 영향을 미친다.
> 
- 이러한 시스템에서 메모리를 동등하게 대우하면 NUMA 구조를 고려한 메모리 할당 알고리즘을 사용하는 시스템에서보다 CPU가 메모리에 접근할 때 대기 시간이 매우 길어지게 된다.

<br/>

<br/>

> 모든 수정의 목표
> 
- 프로세스가 실행 중인 CPU에 “가능한 가장 가까운” 메모리 프레임이 할당되도록 하는 것이다.
    - ***가까운***의 정의는 “최소 지연시간을 가진”으로 하자.

<br/>

<br/>

> NUMA를 고려하면 스케줄러는 프로세스가 마지막으로 실행된 CPU를 추적해야만 한다.
> 
- 스케줄러는 각 프로세스를 직전에 실행된 CPU에 스케줄하고, 가상 메모리 시스템은 스케줄 된 CPU와 가까운 프레임을 할당한다면? → 캐시 적중률이 높아지고 메모리 접근 시간이 감소하게 된다!


<br/>

<br/>

# 💡 스래싱 _Thrashing

> 프로세스에 충분한 프레임이 없는 경우를 고려해보자.
> 
- 작업 집합의 페이지를 지원하는 데 필요한 최소 프레임도 없는 경우면 어떨까?
    - 반복해서 페이지 폴트가 발생! → 이러한 **과도한 페이징을 스래싱**이라 한다.

<br/>

<br/>

## 스래싱의 원인

> 운영체제는 CPU의 이용률을 감시한다.
> 
- CPU 이용률이 너무 낮으면 OS는 다중 프로그래밍의 정도를 증가할 필요가 있다고 생각하고, 새로운 프로세스를 시스템에 추가한다.

<br/>

<br/>

> 스래싱이란?
> 
- 프로세스가 실제로 사용하는 프레임 수만큼의 프레임을 가지지 못해, 계속적으로 페이지 폴트가 발생해 페이지 교체가 일어나는 현상!

<br/>

<br/>

> 동작 방식
> 
- 다중 프로그래밍의 정도가 높아짐에 따라 CPU의 이용률이 높아지다가 스래싱이 일어나면 CPU 이용률이 급격히 저하한다.
    - → 프로세스 실행보다 페이지 교체에 보내는 시간이 더 크기 때문!
        
        <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-17.png" width = 500/>

        
<br/>

<br/>


> 스래싱 현상의 방지
> 
- 각 프로세스가 필요로 하는 프레임을 제공해야 한다.
- 어떻게 각 프로세스가 필요로 하는 프레임의 수를 알 수 있는가?
    - → 작업 설정 방법
        - 프로세스 실행의 **지역성 모델**을 기반으로 한다!

<br/>

<br/>

## 작업 집합 모델

- 메모리 참조 패턴의 지역성
    
    <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-18.png" width = 500/>

    
<br/>

<br/>

- **작업 집합**이란?
    - 프로그램 지역성(`locality`)의 지역의 근사치!
        
        <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-19.png" width = 500/>

        
    
<br/>

<br/>


> 작업 집합 모델의 사용
> 
- 운영체제는 각 프로세스의 작업 집합을 감시하고, 각 프로세스에게 작업 집합의 크기에 맞는 충분한 프레임을 할당한다.
    - D : 전체 요구 프레임, m : 유효한 총 프레임 수
    - D > m → 스래싱 발생!

<br/>

<br/>

## 페이지 폴트 빈도

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-20.png" width = 500/>


> 페이지 폴트 비율 조절
> 
- 페이지 폴트 비율이 너무 높으면?
    - → 프로세스가 더 많은 프레임을 필요로 하는 것
- 페이지 폴트 비율이 너무 낮으면?
    - → 프로세스가 너무 많은 프레임을 갖고 있다는 것
- 페이지 폴트 비율의 상한과 하한을 둔다.
    - 상한을 넘으면?
        - → 프레임을 더 할당
    - 하한보다 낮으면?
        - → 프레임을 회수!


<br/>

<br/>

# 💡 메모리 압축 _Memory Compression

> 페이징의 대안은 메모리 압축이다.
> 
- 여기서는 수정된 프레임을 스왑 공간으로 페이징 아웃하지 않고 여러 프렝미을 하나의 프레임으로 압축한다.
    - → 시스템이 페이지 스와핑에 의존하지 않고도 메모리 사용량을 줄일 수 있음!

<br/>

<br/>

- 압축 이전
    
    <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-21.png" width = 500/>

    
<br/>

<br/>


- 압축 이후
    
    <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-22.png" width = 500/>

    

<br/>

<br/>

> 앞서 말했듯 모바일 시스템은 스와핑을 지원하지 않는다.
> 
- 따라서 메모리 압축은 Android 및 iOS를 포함한 모바일 운영체제의 메모리 관리 전략의 핵심이다!
    - 또한 Windows 10과 macOS는 모두 메모리 압축을 지원한다.
    - Windows 10의 경우 Microsoft는 **UWP**(Universal Windows Platform) 아키텍처를 개발함!


<br/>

<br/>

# 💡 커널 메모리의 할당 _Allocating Kernel Memory

> 커널 메모리는 보통 사용자 모드 프로세스에 할당해 주기 위한 페이지 리스트와는 별도의 메모리풀에서 할당받는다.
> 
- 이렇게 하는 이유는 다음과 같다.
    1. 커널은 다양한 크기의 자료구조를 위해 메모리를 할당받는다.
        - 이 자료구조들은 페이지 크기보다 작은 크기를 갖기도 한다.
        - 그 때문에 커널은 메모리를 조심스럽게 사용하여야 하고, 단편화에 의한 낭비를 최소화하고자 한다.
        - 많은 운영체제가 커널 코드나 데이터를 페이징하지 않기 때문에 특히 더 중요하다.
    2. 사용자 모드 프로세스에 할당되는 페이지들은 물리 메모리상에서 굳이 연속된 것일 필요가 없다.
        - 그러나 가상 메모리 인터페이스를 통하지 않고 물리 메모리에 직접 접근하는 특정 하드웨어 장치는 물리적으로 연속적인 메모리가 있어야 하는 경우가 있다.

<br/>

<br/>

***→ 커널 프로세스에 할당되는 메모리를 관리하는 두 가지 기법에 대해 살펴보자!***

<br/>

<br/>

## 버디 시스템

> 버디 시스템은 물리적으로 연속된 페이지들로 이루어진 고정된 크기의 세그먼트로부터 메모리를 할당받는다.
> 
- 메모리는 2의 거듭제곱 할당기에 의해 2의 거듭제곱 단위로 할당된다.
    - 일반 크기의 메모리 요구는 가장 가까운 2의 거듭제곱 크기로 올림된다.
        
        <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-23.png" width = 500/>
        

<br/>

<br/>

- 할당 방식
    
    <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-24.png" width = 500/>
    
<br/>

<br/>


## 슬랩 할당

> 슬랩(Slab)이란?
> 
- 하나 또는 그 이상의 물리적으로 연속된 페이지들로 구성된다.

<br/>

<br/>

> 캐시(Cache)
> 
- 하나 혹은 그 이상의 슬랩들로 구성된다.
- 각 캐시는 단일 타입의 객체를 포함한다.
    
    <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-25.png" width = 500/>
    
<br/>

<br/>


> 슬랩 할당 알고리즘은 커널 객체를 저장하기 위해 캐시를 사용한다.
> 
- 캐시가 생성되면 초기에는 미사용(free)이라고 표시된 몇 개의 객체들이 캐시에 할당된다.
    - 캐시 내의 객체의 수는 해당 슬랩의 크기에 좌우된다.
- 슬랩은 Full, Empty, Partial 세 가지 중 한 상태에 있게 된다.

<br/>

<br/>

> 슬랩 할당기의 장점
> 
- 단편화에 의해 낭비되는 메모리가 없다.
    - 커널이 메모리 할당을 요구할 때마다 정확히 필요한 만큼의 메모리 만을 할당한다.
- 메모리 요청이 빠르게 처리된다.
    - 할당과 해제가 빈번한 자료구조 객체를 관리하는 데 특히 효율적이다.


<br/>

<br/>

# 💡 기타 고려 사항 _Other Considerations

> 페이징 시스템이 효과적으로 실행되기 위해서는 기타 고려 사항이 많이 있다.
> 

<br/>

<br/>

## 프리페이징

> **프리페이징**은 높은 수준의 초기 페이징을 방지하려는 시도이다.
> 
- 이 전략은 필요한 페이지의 일부 또는 전부를 한 번에 메모리에 가져오는 것이다.

<br/>

<br/>

> 프리페이징은 때에 따라 이점을 제공할 수 있다.
> 
- 문제는 단순히 프리페이징을 사용하느 비용이 해당 페이지 폴트를 처리하는 비용보다 작은지 여부이다.
    - 프리페이징에 의해 메모리로 가져온 많은 페이지가 사용되지 않는 경우가 있다.

<br/>

<br/>

## 페이지 크기

> 이미 존재하는 시스템의 운영체제는 페이지 크기를 바꾸는 것이 거의 불가능하다.
> 
- 그러나 새 시스템을 개발할 때는 페이지 크기를 결정해야 한다.
    - 한 개의 페이지 크기가 모든 시스템에 최적일 수는 없다.

<br/>

<br/>

> 할당해 준 메모리 사용 효율을 위해서는 작은 페이지가 좋다.
> 
- 다른 문제는 페이지를 읽거나 쓰는 데 필요한 시간이다.

<br/>

<br/>

## TLB Reach

> **TLB reach**는 TLB로부터 액세스할 수 있는 메모리 공간의 크기를 뜻한다.
> 
- 이는 TLB에 있는 항목 수에 페이지 크기를 곱한 것이다.
    - 이상적으로는 한 프로세스의 작업 집합이 TLB에 다 들어올 수 있으면 가장 좋다.

<br/>

<br/>

> TLB reach를 늘리는 또 다른 방법 → 페이지 크기를 늘리거나 여러 페이지 크기를 제공한다!
> 
- 예를 들어 Linux의 기본 페이지 크기는 4KB이다.
    - 그러나, 더 큰 페이지가 사용될 수 있는 물리 메모리 영역을 지정하는 **거대 페이지**도 제공한다.

<br/>

<br/>

## 역 페이지 테이블

> 이 테이블은 <process-id, page-number>에 의해 색인되며 각 물리 메모리마다 한 항목을 갖는다.
> 
- 각 페이지 프레임에 어떤 가상 메모리 페이지가 저장되어 있는지의 정보만 유지하면 된다.

<br/>

<br/>

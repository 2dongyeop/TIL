# 가상 메모리
> 가상 메모리(`virtual memory`)란?
>
>→ 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법이다. 
>
>→ 주요 장점은 하나는 사용자 프로그램이 물리 메로리보다 커져도 된다는 점이다! 

<br/>

<br/>

## 💡 배경 _Background

> 실행 중인 코드는 반드시 물리 메모리에 있어야 한다는 것은 일견 필요하고 타당한 요구 조건으로 보이지만, 프로그램의 크기를 물리 메모리의 크기로 제한한다는 점 때문에 마냥 좋은 요구 조건은 아니다.
> 

<br/>

<br/>

> 실제 프로그램을 살펴보면 많은 경우에 프로그램 전체가 한꺼번에 메모리에 늘 올라와 있어야 한다는 건 아님을 쉽게 발견할 수 있다.
> 
- 프로그램에 잘 발생하지 않는 오류 상황을 처리하는 코드가 종종 존재한다.
    - 이런 오류들은 실질적으론 거의 발생하지 않는다.
- 배열, 리스트, 테이블 등은 필요 이상으로 많은 공간을 점유할 수도 있다.
- 프로그램 내의 어떤 옵션이나 기능들은 거의 사용되지 않는다.

<br/>

<br/>

> 만일 프로그램을 일부분만 메모리에 올려놓고 실행할 경우의 얻는 이점
> 
- 프로그램은 물리 메모리 크기에 의해 더는 제약받지 않게 된다.
    - → 사용자들은 매우 큰 ***가상*** 주소 공간을 가정하고 프로그램을 만들 수 있다.
- 각 프로그램이 더 작은 메모리를 차지하므로 더 많은 프로그램을 동시에 수행할 수 있게 된다.
- 프로그램을 메모리에 올리고 스왑하는데 필요한 I/O 회수가 줄어들기 때문에 프로그램 실행이 빠르다.

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-background1.png" width = 500/>


> **가상 메모리**는 실제의 물리 메모리 개념과 개발자의 논리 메모리 개념을 분리한 것이다.
> 
- 이로써 작은 메모리를 가지고도 얼만든지 큰 가상 주소 공간을 프로그래머에게 제공할 수 있다는 점이다.

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-background2.png" width = 500/>

> 한 프로세스의 **가상 주소 공간**은 그 프로세스가 메모리에 저장되는 논리적인 모습(view)을 말한다.
> 
- 일반적으로 위 그림과 같이 특정 논리 주소에서 시작하여 연속적인 공간을 차지한다.
    - 힙과 스택 사이의 공백도 가상 주소 공간의 일부이다. (**성긴 주소 공간**)

<br/>

<br/>

> 가상 메모리는 페이지 공유를 통해 프로세스들에게 (파일 또는 메모리) 공유를 제공한다.
> 
- 표준 C 라이브러리와 같은 시스템 라이브러리가 여러 프로세스들에 공유되는 것이 예시이다.
- 마찬가지로 프로세스들이 메모리를 공유할 수 있다! → 아래 사진 참고
    
    <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-background3.png" width = 500/>


<br/>

<br/>

# 💡 요구 페이징 _Demand Paging

> 어떻게 실행 프로그램을 보조저장장치에서 메모리로 적재할 수 있을까?
> 
- → 필요한 페이지만 적재하자! = ***요구 페이징(demand paging)***
    - 일반적으로 가상메모리 시스템에서 사용되며, **필요할 때**만 페이지가 적재된다.

<br/>

<br/>

## 기본 개념

> 요구 페이징의 기본 개념은 필요할 때만 페이지를 메모리에 적재하는 것이다.
> 
- 결과적으로 프로세스가 실행되는 동안 일부 페이지는 메모리에 있고 일부는 보조저장장치에 있다.
    
    <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-background4.png" width = 500/>

    

<br/>

<br/>

> 그러나 프로세스가 메모리에 올라와 있지 않은 페이지에 접근하려고 하면 어떤 일이 발생할까?
> 
- ***페이지 폴트*** 트랩 발생!
    - 페이지 테이블 항목이 무효로 설정되어 있을 때를 의미.

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-background5.png" width = 500/>


<br/>

<br/>

> 페이지 폴트를 처리하는 과정
> 
1. 프로세스에 대한 내부 테이블을 검사해서 그 메모리 참조가 유효인지 무효인지 검사
2. 만약 무효한 페이지에 대한 참조라면 그 프로세스는 중단된다.
    1. 유효한 참조인데 페이지가 아직 메모리에 올라오지 않았다면, 보조저장장치로부터 가져와야 한다.
3. 빈 공간, 즉 가용 프레임을 찾는다.
4. 보조저장장치에 새로이 할당된 프레임으로 해당 페이지를 읽어 들이도록 요청한다.
5. 보조저장장치 읽기가 끝나면, 이 페이지가 이제는 메모리에 있다는 것을 알리기 위해 페이지 테이블을 갱신하며, 프로세스가 유지하고 있는 내부 테이블을 수정한다.
6. 트랩에 의해 중단되었던 명령어를 다시 수행한다.

<br/>

<br/>

> 극단적인 경우: 메모리에 페이지가 ***하나도*** 안 올라와있는 상태에서도 프로세스를 실행할 수 있음!
> 
- OS에서 명령 포인터의 값을 프로세스의 첫 명령으로 설정하는 순간?
    - → 이 명령이 메모리에 존재하지 않는 페이지에 있으므로, 페이지 폴트를 발생!
- 페이지가 적재되고 나면 프로세스는 수행을 계속하는데, 페이지를 필요할 때마다 폴트가 발생
    - 일단 필요한 모든 페이지가 적재되고 나면 더 폴트가 발생하지는 않는다.
    - 이것이 순수 요구 페이징(`pure demand paging`)이다.

<br/>

<br/>

> 프로그램들은 한 명령어에서도 여러 개의 페이지 폴트를 일으킬 수 있다.
> 
- 다행히 실행중인 프로세스들을 분석해보면 이러한 경우는 거의 발생하지 않는다.
    - 모든 프로그램은 **참조의 지역성**이라는 성질이 있어 어느 한 특정 작은 부분만 한동안 집중적으로 참조하는데, 이러한 성질 덕에 요구 페이징은 만족할 만한 성능을 보인다.

<br/>

<br/>

> 요구 페이징을 지원하기 위해 필요한 하드웨어는 페이지오가 스와핑을 위한 하드웨어와 동일하다.
> 
- 페이지 테이블 : 보호 비트들 특별한 값 또는 유효/무효 비트를 통해 특정 항목을 무효로 설정할 수 있다.
- 보조저장장치 : 메인 메모리에 없는 모든 페이지를 가지고 있다.
    - 보통 고성능 디스크 또는 NVM 장치로, 스왑 장치라고도 한다.
    - 이 목적을 위해 사용되는 저장장치 영역을 **스왑 공간**이라고 한다

<br/>

<br/>

> 한 명령어가 많은 기억 장소를 변경하는 것일 때에는 상당히 어려운 문제가 발생한다.
> 
- 이러한 문제는 두 가지 해결법이 있다.
    1. 마이크로코드로 양 블록의 두 끝을 계산해 겹치지 않는 것을 확인하기
        1. 만약 페이지 폴트가 발생할 가능성이 있다면 미리 페이지 폴트를 발생시킨다.
        2. 그 후에 이동을 시작하면 어떤 페이지 폴트도 일어날 수 없다.
    2. 이동에 의해서 이전의 내용이 지워질 기억 장소드의 값을 보존하기 위해 임시 레지스터들을 사용하기
        1. 복구의 용도로 사용

<br/>

<br/>

## 가용 프레임 리스트

> 페이지 폴트가 발생하면 운영체제는 요청된 페이지를 보조저장장치에서 메인 메모리로 가져와야 한다.
OS는 페이지 폴트를 해결하기 위해 가용 프레임의 풀인 **가용 프레임 리스트**를 유지한다.
> 
- 프로세스의 스택 또는 힙 세그먼트가 확장될 때도 가용 프레임이 할당 되어야 한다!
    - OS는 일반적으로 **zero-fill-on-demand**라는 기법을 사용!
        
        <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-background6.png" width = 500/>

        
    - 여기서 `Zero-fill-on-demand` 프레임은 할당되기 전에 0으로 모두 채워져 이전 내용이 지워진다.

<br/>

<br/>

## 요구 페이징의 성능

> 요구 페이징은 컴퓨터 시스템의 성능에 큰 영향을 줄 수 있다.
> 

→ 요구 페이지 메모리에 대한 **실질 접근 시간**을 계산해보자.

<br/>

<br/>

> 페이지 폴트의 확률 p(0 ≤ p ≤1)
> 
- 실질 접근 시간 = (1-p) * ma + p * 페이지 폴트 시간

<br/>

<br/>

> 페이지 폴트의 처리 순서
> 
1. 운영체제에 트랩을 요청
2. 레지스터들과 프로세스 상태를 저장
3. 인터럽트 원인이 페이지 폴트임을 알아냄
4. 페이지 참조가 유효한 것인지 확인하고, 보조저장장치에 있는 페이지의 위치를 알아냄.
5. 저장장치에 가용 프레임으로의 읽기 요구를 냄
    1. 읽기 차례가 돌아오기까지 대기 큐에서 기다린다.
    2. 디스크에서 찾는 시간과 회전 지연 시간 동안 기다린다.
    3. 가용 프레임으로 페이지 전송을 시작한다.
6. 기다리는 동안 CPU 코어는 다른 사용자에게 할당
7. 저장장치가 다 읽었다고 인터럽트를 검
8. 다른 프로세스의 레지스터들과 프로세스 상태를 저장
9. 인터럽트가 보조저장장치로부터 왔다는 것을 알아냄
10. 새 페이지가 메모리로 올라왔다는 것을 페이지 테이블과 다른 테이블들에 기록
11. CPU 코어가 자기 차례로 오기까지 다시 기다림
12. CPU 차례가 오면 위에서 저장시켜 두었던 레지스터들, 프로세스 상태, 새로운 페이지 테이블을 복원시키고 인터럽트 되었던 명령어를 다시 실행

<br/>

<br/>

> 어떤 경우에도, 페이지 폴트 처리 시간은 다음 3개의 주요 작업 요소로 이루어져 있음을 알 수 있다.
> 
1. 인터럽트의 처리
2. 페이지 읽기
3. 프로세스 재시작

<br/>

<br/>

> 실질 접근 시간 구하기 예시
> 
- 평균 페이지 폴트 처리 시간이 8밀리초이고, 메모리 접근 시간이 200나노초 임을 가정
- 실질 접근 시간 = (1-p) * 200 + p * (8milliseconds)
= (1-p) * 200 + p * 8,000,000 = 200 + 7,999,800 * p

<br/>

<br/>

**→ 실제 접근 시간은 페이지 폴트율에 비례한다!**

> 요구 페이징의 또 다른 특성 중 하나는 스왑 공간의 관리이다.
> 
- 스왑 공간에서의 디스크 I/O은 일반적으로 파일 시스템에서의 입출력보다 빠르다.
    - → 스왑 공간은 파일 시스템보다 더 큰 블록을 사용하기 때문!
    - 또 스왑 공간과 입출력을 할 때는 파일 찾기나 간접 할당 방법 등을 사용하지 않기 때문!

<br/>

<br/>

> 어떤 시스템들은 실행 파일을 스왑 공간에 넣지 않음으로써 스왑 공간의 크기를 줄이기도 한다.
> 
- 실행 파일로부터 요구 페이지를 요청하면 파일 시스템으로부터의 그 페이지를 직접 가져온다.
- 이 페이지들의 교체가 필요하면 이들 페이지에 새 페이지의 내용을 덮어쓸 수 있다.
- 페이지가 다시 필요해지면 추후 파일 시스템으로부터 다시 읽어 들일 수 있다.
    - → 이러한 방식에선 파일 시스템이 백업 저장장치로 사용됨!
    - 그러나 스왑 공간은 여전히 파일과 관련이 없는 페이지 때문에 필요하다.
        - → 이러한 메모리를 **익명(anonymous) 메모리**라고 한다.


<br/>

<br/>

# 💡 쓰기 시 복사 _Copy-on-Write

> `fork()` 시스템콜은 부모 프로세스와 똑같은 자식 프로세스를 만들어 주는 것임을 상기하라.
> 
- 과거엔 `fork()` 를 하면 부모 프로세스의 페이지들을 실제로 자식에 복사 → 자식의 주소 공간을 구성!
    - 하지만 대부분의 자식은 이렇게 만들어지자마자 `exec()` 시스템 콜을 한다.
    - → 이러면 부모로부터 복사해온 페이지들이 다 쓸데없어짐!
    - 그래서 부모의 페이지들을 복사해오는 대신 **쓰기 시 복사 방식**을 사용할 수 있다!

<br/>

<br/>

> 쓰기 시 복사는 자식 프로세스가 시작할 때 부모의 페이지를 당분간 함께 사용하도록 한다.
> 
- 이때 공유되는 페이지를 쓰기 시 복사 페이지라고 표시한다.
- ***둘 중 한 프로세스가 공유중인 페이지에 쓸 때 그 페이지의 복사본이 만들어진다는 의미!***

<br/>

<br/>

- 공유 페이지 사용 전
    
    <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-7.png" width = 500/>

<br/>

<br/>

    
- 공유 페이지 사용 후
    
    <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-8.png" width = 500/>

<br/>

<br/>

# 💡 페이지 교체 _Page Replacement

> 다중 프로그래밍 정도를 더 올리면, **메모리 과할당**(`over-allocating`)이 발생한다.
> 
- 10개의 페이지 중 5개만을 사용하는 6개의 프로세스를 실행시키면?
    - → 10개의 프레임은 남겨놓고도 높은 CPU 활용률과 처리율을 얻을 수 있다.
    - 그러나 특정 데이터 조합에 대해 이 프로세스들이 10페이지 모두를 사용해야 하는 상황이 발생할 수 있고, 이러면 40프레임만이 존재하는 상황에서 60프레임을 필요로 하게 된다.

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-9.png" width = 500/>

> 얼마만큼의 메모리를 I/O 용도로 할당하고, 얼마만큼을 프로그램에 할당하는가는 매우 중요하다.
> 
- 메모리의 초과 할당은 다음과 같이 나타난다.
    - 프로세스가 실행되는 동안 페이지 폴트 발생
    - OS는 필요로 하는 페이지가 보조저장장치에 저장된 위치를 알아내지만,
    가용한 프레임 목록에 ***가용한 프레임이 없음***을 발견
        - → 즉, 모든 메모리가 사용중!

<br/>

<br/>

- 이 시점에서 OS는 몇 가지 선택을 할 수 있다.
    1. 프로세스를 종료할 수 있다.
        1. 단, 요구 페이징은 시스템의 활용률과 처리율을 올리기 위해 운영체제가 선택한 방법이다.
        2. 사용자가 그들의 프로세스가 페이징 시스템에서 실행되고 있음을 알게 해선 안된다.
        3. 따라서 좋은 방법이 아님!
    2. 표준 스와핑을 사용해 프로세스를 스왑아웃하여 모든 프레임을 비우고 다중 프로그래밍 정도를 줄인다.
        1. 대부분의 운영체제는 **페이징 스와핑과 페이지 교체를 결합**한다.

<br/>

<br/>

## 기본적인 페이지 교체

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-10.png" width = 500/>

> 페이지 폴트 서비스 루틴이 페이지 교체를 포함해 아래와 같이 수정되어야 한다.
> 
1. 보조저장장치에서 필요한 페이지의 위치를 알아낸다.
2. 빈 페이지 프레임을 찾는다.
    1. 비어 있는 프레임이 있다면 그것을 사용한다.
    2. 비어 있는 프레임이 없담녀 **희생될(victim) 프레임**을 선정하기 위해 페이지 교체 알고리즘을 가동
    3. 희생될 페이지를 보조저장장치에 기록, 관련 테이블을 수정
3. 빼앗은 프레임에 새 페이지를 읽어오고 테이블을 수정한다.
4. 페이지 폴트가 발생한 지점에서부터 프로세스를 계속한다.

<br/>

<br/>

> ***빈 프레임이 없는 경우엔 디스크를 두 번 접근해야 한다는 사실에 주의하자!***
> 
- 이러한 오버헤드는 **변경 비트**를 사용해 감소시킬 수 있다.
    - 각 페이지나 프레임은 그걳과 관련된 변경 비트를 하드웨어에 가지게 된다.
    - 변경 비트는 어떤 바이트라도 내용을 쓰면 페이지가 변경되었음을 나타낸다.

<br/>

<br/>

> 페이지 교체는 요구 페이징의 기본이다.
> 
- 이를 통해 논리적 메모리와 물리 메모리 간의 분리가 완성된다.
- 이 기법을 통해 매우 작은 물리 메모리로도 프로그래머에게 광대한 가상 메모리를 제공할 수 있다!

<br/>

<br/>

> 요구 페이징 시스템은 중요한 두 가지 문제를 해결해야 한다.
> 
1. 프레임 할당 알고리즘
2. 페이지 교체 알고리즘
    
    → 즉, 여러 프로세스가 존재하는 경우 각 프로세스에 얼마나 많은 프레임을 할당해야 할지 결정
    
    → 또한 페이지 교체가 필요할 때마다 어떤 페이지를 교체해야 할 지 결정해야 한다.
    

<br/>

<br/>

> 페이지 교체 알고리즘의 성능 평가
> 
- 특정 메모리 참조 나열에 대해 알고리즘을 적용하여, 페이지 폴트 발생 횟수를 계산해 평가한다.
    - → 이러한 메모리 주소의 나열을 참조열이라 부른다.
    - → 참조열은 인공적으로 생성할 수도 있고, 주어진 시스템을 추적하여 매 메모리 참조 시의 주소를 기록할 수도 있다.

<br/>

<br/>

## FIFO 페이지 교체

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-11.png" width = 500/>

> 가장 간단한 알고리즘으로, 페이지를 교체해야 할 때 메모리에 올라온 지 가장 오래된 페이지를 내쫓는다.
> 
- 페이지가 올라온 시간을 페이지마다 기록해도 되고, 큐를 만들어 가지고 있어도 된다.

<br/>

<br/>

> FIFO 페이지 교체 알고리즘은 이해하기도 쉽고, 프로그래밍하기도 쉽다!
> 
- 그러나 성능이 항상 좋지는 않다.
    - 교체된 페이지가 오래전 사용된 뒤 더는 사용되지 않았던 초기화 모듈일 수도 있고,
    - 반대로 교체된 페이지가 초기화된 뒤 계속 자주 사용되는 변수를 포함하고 있을 수도 있다!

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-12.png" width = 500/>

> 페이지 폴트율 대 할당된 프레임 수 간의 그래프
> 
- 그래프를 보면 **Belady의 모순(Belady’s anomaly)**이 일어난 것을 볼 수 있다.
    - 이는 프로세스에 **프레임을 더 주었는데 오히려 페이지 폴트율은 더 증가하는 현상**을 말한다.

<br/>

<br/>

## 최적 페이지 교체

> Belady의 모순이 가져온 결과 중 하나는 **최적 교체 정책**에 대한 탐색이다.
> 
- 최적 교체 정책이란 모든 알고리즘보다 낮은 페이지 폴트율을 보이며 Belady의 모순이 발생하지 않는다!
    - OPT 또는 MIN으로 불린다.
    - 이를 요약하면 **“ 앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체하라. “** 이다.
        
        <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-13.png" width = 500/>
        

<br/>

<br/>

> ***안타깝게도 이 알고리즘의 실제 구현은 어렵다.***
> 
> 
> ***→ 프로세스가 앞으로 메모리를 어떻게 참조할 것인지를 미리 알아야 하기 때문!***
> 

<br/>

<br/>

## LRU 페이지 교체

> 최적 알고리즘의 근사 알고리즘
> 
- FIFO와 OPT 알고리즘의 결정적인 차이
    - FIFO : 알고리즘이 페이지가 메모리로 들어온 시간을 이용
    - OPT : 페이지가 ***사용될*** 시간을 이용

→ 최근의 과거를 가까운 미래의 근사치로 본다면, ***가장 오랜 기간 동안 사용되지 않은 페이지를 교체***하자!

= `Least-recently-used(LRU)` 알고리즘

<br/>

<br/>

> LRU 알고리즘은 페이지마다 마지막 사용 시간을 유지한다.
> 
- 페이지 교체 시에 LRU는 가장 오랫동안 사용되지 않은 페이지를 선택한다.
- 이 정책은 미래 대신 과거 시간에 대해 적용한 최적 교체 정책으로 생각할 수 있다.

<br/>

<br/>

> LRU 정책은 페이지 교체 알고리즘으로 자주 사용되며 좋은 알고리즘으로 인정받고 있다.
> 
- 문제는 ***어떻게*** 이 알고리즘을 구현하느냐 하는 것이다.
    - 이 알고리즘은 하드웨어의 지원이 필요하다!
    - 프레임들을 최근 사용된 시간 순서로 파악할 수 있어야 하는 것이다.

<br/>

<br/>

> 두 가지 구현 방법
> 
- 계수기(`counter` ) :
    - 가장 간단한 방법으로, 각 페이지 항목마다 사용 시간 필드를 넣고 CPU에 논리적인 시계나 계수기를 추가한다.
    - 메모리가 접근될 때마다 시간은 증가한다.
    - 페이지에 대한 참조가 일어날 때마다 페이지의 사용 시간 필드에 시간 레지스터의 내용이 복사된다.

<br/>

<br/>

- 스택(`stack` ) :
    - LFU 교체 정책의 다른 구현 방법은 페이지 번호의 스택을 유지하는 방법이다.
    - 페이지가 참조될 때마다 페이지 번호는 스택의 중간에서 제거되어 꼭대기(top)에 놓이게 된다.

<br/>

<br/>

> 최적 교체와 마찬가지로 LRU는 Belady의 모순 현상을 야기하지 않는다.
> 
- 페이지 교체 알고리즘 중에는 Belady의 모순 현상을 나타내지 않는 것들이 있다.
    - 이러한 알고리즘들을 **스택 알고리즘**이라고 부른다.

<br/>

<br/>

> 양쪽 LRU 구현 방법 모두 반드시 표준적인 TLB 레지스터 이상의 하드웨어 지원이 있어야 한다.
> 
- 계수기 값과 스택을 갱신하는 일을 메모리 참조 때마다 수행되어야 한다.

<br/>

<br/>

## LRU 근사 페이지 교체

> LRU 페이지 교체 지원을 충분히 할 수 있는 하드웨어는 많지 않다.
어떤 시스템에서는 전혀 하드웨어적인 지원을 하지 않고 다른 알고리즘을 쓸 수 밖에 없다.
> 
- → 그러나 많은 시스템은 **참조 비트**의 형태로 어느 정도 지원은 하고 있다!

<br/>

<br/>

### 부가적 참조 비트 알고리즘

> 일정한 간격마다 참조 비트들을 기록함으로써 추가적인 선후 관계 정보를 얻을 수 있다.
> 

<br/>

<br/>

- 동작 방식
    - 각 페이지에 대해 8비트의 참조 비트를 할당한다.
    - 일정한 시간 간격마다, 타이머 인터럽트를 걸어 운영체제가 참조 비트를 8비트 정보의 최상위 비트로 이동시키고, 나머지 비트들은 하나씩 오른쪽으로 이동시킨다.
        - 이 8비트 값을 정수로 생각한다면 가장 작은 수를 갖는 페이지가 LRU 페이지이고, 교체할 수  있다

<br/>

<br/>

- 물론 사용하는 비트 수는 달라질 수 있고, 갱신을 가능한 가장 빠르게 하기 위한 크기가 선택된다.
    - 극단적인 경우 0이 될 수 있고, 이 경우는 참조 비트만이 남게 된다.
    - 이 알고리즘을 **2차 기회 알고리즘**이라 부른다.

<br/>

<br/>

### 2차 기회 알고리즘

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/10-14.png" width = 500/>

> 2차 기회 알고리즘의 기본은 FIFO 교체 알고리즘이다.
> 
- 그러나 페이지가 선택될 때마다 참조 비트를 확인한다.
    - 참조 비트가 0이면 → 페이지를 교체
    - 참조 비트가 1이면 → 다시 한번 기회를 주고 다음 FIFO 페이지로 넘어간다.
        - 한번 기회를 받게 되면 참조 비트는 해제되고 도착 시간이 현재 시각으로 재설정된다.

<br/>

<br/>

- 이에 따라 그 페이지는 다른 모든 페이지가 교체될 때까지 교체되지 않는다.
    - 따라서, 참조 비트가 계속 설정되어 있을 정도로 자주 사용되는 페이지는 전혀 교체되지 않을 것이다.

<br/>

<br/>

> 2차 기회 알고리즘을 구현하는 하나의 방법은 순환 큐를 이용하는 것이다.
> 
- 이 큐에는 포인터가 있어 다음에 교체될 페이지를 가리킨다.
    - 최악의 경우, 모든 비트가 1값을 가지고 있었으면 포인터는 큐를 완전히 한바퀴 돈다.
    - 그러고 나면 모든 페이지는 기회가 주어지게 된다.
        - 두 번째 돌 때는 사실상 FIFO와 같은 것이 된다.

<br/>

<br/>

### 개선된 2차 기회 알고리즘

> 참조 비트와 변경 비트를 사용해 더 개선할 수 있다.
> 
- 이 두 개의 비트를 조합해 사용하면 네 가지의 등급이 가능하다!
    - (0, 0) : 최근의 사용되지도 변경되지도 않은 경우 → 교체하기 가장 좋은 페이지
    - (0, 1) : 최근에 사용되지는 않았지만 변경은 됨 → 이 페이지는 뺏어 오려면 디스크에 내용을 기록해야 함
    - (1, 0) : 최근에 사용은 되었으나 변경은 되지 않은 경우 → 이 페이지는 곧 다시 사용될 가능성이 높음
    - (1, 1) : 최근에 사용도 되었고 변경도 된 경우 → 아마 곧 다시 사용될 것이며 뺏으려면 역시 디스크에 그 내용을 먼저 기록해야 함.

<br/>

<br/>

## 계수-기반 페이지 교체

> 페이지 교체를 위해 사용되는 많은 다른 알고리즘이 있다.
> 
<br/>

<br/>

- **LRU 알고리즘**
    - 참조 횟수가 가장 적은 페이지를 교체하는 방법이다.
    - 어떤 프로세스가 그 초기 단계에서는 한 페이지를 집중적으로 많이 사용하지만 그 후로 다시는 이 페이지를 사용하지 않는 경우에 판단이 빗나갈 수 있다.
    - 한 가지 해결책
        - 참조 횟수를 일정한 시간마다 하나씩 오른쪽으로 시프트해서 지수적으로 그 영향력을 줄이기!

<br/>

<br/>

- **MFU 알고리즘 (Most Frequently Used)**
    - 가장 작은 참조 횟수를 가진 페이지가 가장 최근 참조된 것이고 앞으로 사용될 것이라는 판단에 근거
    - 일반적으로 잘 쓰이지 않는다.
        - 구현 비용이 많이 들고, OPT에 근사하지도 않기 때문

<br/>

<br/>

## 페이지-버퍼링 알고리즘

> 페이지 교체 알고리즘과 병행해 여러 가지 버퍼링 기법이 사용될 수 있다.
> 
<br/>

<br/>

- 시스템이 가용 프레임 여러 개를 풀로 가지고 있다가, 페이지 폴트가 발생하면 예전과 마찬가지로 교체될 페이지를 찾지만, 교체될 페이지의 내용을 디스크에 기록하기 전에 가용 프레임에 새로운 페이지를 먼저 읽어 들이는 방법이다.
    - 위 방법의 확장 → 변경된 페이지 리스트를 유지하는 방법도 있다.
        - 페이징 장치가 아무런 일도 없게 되면 그때마다 변경된 페이지들을 차례로 보조저장장치에 쓴 후에, 페이지의 변경 비트를 0으로 되돌려 놓는다.

<br/>

<br/>

- 다른 방법은 가용 프레임 풀을 유지하지만 그 풀 속 프레임의 원래 임자 페이지가 누구였었는지 기록하기!
    - 풀 속의 프레임 내용은 그것을 보조저장장치에 썼다고 하더라도 수정되지 않았을 확률이 있다.

<br/>

<br/>

## 응용(application)과 페이지 교체

> 몇몇 경우에는 운영체제의 가상 메모리를 통해 데이터에 접근하는 응용이 운영체제가 전혀 버퍼링 기능을 제공하지 않는 경우에 비해 오히려 안 좋은 성능을 보일 때가 있다.
> 

<br/>

<br/>

- 이러한 문제들 때문에, 몇몇 운영체제는 특별한 프로그램들에는 보조저장장치 파티션을 파일 시스템 구조가 아닌 단순한 논리적인 블록들의 순차적인 배열로써 사용할 수 있게 해주는 기능을 갖춘다.
    - 이 배열은 종종 **raw disk**라고 불린다.
    - 특정 응용들이 raw 파티션을 이용해 자신만의 특수한 저장장치 서비스를 구현하는 것이 효율적인 데 비해 대부분의 응용은 정상적인 파일 시스템 서비스를 이용해 동작하는 것이 더 좋은 성능을 보임을 알자.


<br/>

<br/>

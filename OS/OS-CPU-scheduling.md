# CPU 스케줄링

CPU 스케줄링(`scheduling`)은 다중 프로그램 운영체제의 기본이다!

- 운영체제는 CPU를 프로세스 간에 교환함으로써, 컴퓨터를 보다 생산적으로 만든다!
- “프로세스 스케줄링”과 “스레드 스케줄링”은 상호 교환적으로 사용되곤 한다.
    - 이 장에서는 일반적 스케줄링 개념을 논의할 때는 “프로세스 스케줄링”을 사용하고,
    - 스레드에 국한된 개념을 가리키는 경우에는 “스레드 스케줄링”이라는 용어를 사용하기로 한다.

<br/>

<br/>

# 💡 기본 개념 _Basic Concepts

앞서 **다중 프로그래밍의 목적**은 **CPU 이용률을 최대화**하기 위해 항상 실행 중인 프로세스를 가진다고 했다.

- 코어가 하나인 시스템에서, 하나의 프로세스가 I/O 요청을 기다린다면?
- CPU는 시간을 낭비하며, 어떤 유용한 작업도 진행하지 못한다! → **CPU 이용률 낭비!**

<br/>

<br/>

다중 프로그래밍은 이러한 낭비를 줄이고, 시간을 생산적으로 활용하려 한다.

- 어떤 프로세스가 대기해야 할 경우, **CPU를 회수**해 다른 프로세스에 할당하고, 이러한 패턴은 반복된다.

<br/>

<br/>

## CPU-I/O 버스트 사이클

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/CPU-IO-burst.png" width = 600/>


CPU 스케줄링의 성공은 프로세스들의 다음과 같은 관찰된 성질에 의해 좌우된다.

- 프로세스 실행은 CPU 실행과 I/O 대기의 **사이클**로 구성된다.
    
    → 프로세스들은 이들 두 상태 사이를 교대로 왔다 갔다 한다.
    
- 프로세스 실행은 **CPU 버스트(burst)**로 시작된다.

    → 이후, **I/O 버스트**가 발생하고, 두 버스트의 발생이 반복된다.
    

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/CPU-burst.png" width = 600/>


CPU 버스트들의 지속 시간을 광범위하게 측정한 결과는 아래와 같다.

- 일반적으로 지수형 또는 초지수형으로 특성화된 곡선을 찾아볼 수 있다.
- **짧은 CPU 버스트가 많이 있으며, 긴 CPU 버스트는 적다.**
    - I/O 중심의 프로그램 : 짧은 CPU 버스트를 많이 가짐
    - CPU 지향 프로그램 : 다수의 긴 CPU 버스트를 가짐

<br/>

<br/>

## CPU 스케줄러

- CPU가 유휴 상태가 될 때마다, OS는 준비 큐의 프로세스 중 하나를 선택해 실행한다.
    - 이 선택은 **CPU 스케줄러**에 의해 수행된다.
    - ***이때, 준비 큐는 반드시 FIFO 방식의 큐가 아니어도 되는 것에 유의하자!***

<br/>

<br/>

## 선점 및 비선점 스케줄링

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/process-state.png" width = 600/>


CPU 스케줄링 결정은 다음의 네 가지 상황에서 발생할 수 있다.

1. 한 프로세스가 실행 상태에서 대기 상태로 전환될 때 (`running → waiting`) : **비선점**
    
    → ex) I/O 요청을 대기해야 할 때
    
2. 프로세스가 실행 상태에서 준비 완료 상태로 전환될 때 (`running → ready`) : **선점**
    
    → ex) 인터럽트가 발생할 때
    
3. 프로세스가 대기 상태에서 준비 완료 상태로 전환될 때 (`waiting → ready`) : **선점**
    
    → ex) I/O 작업 완료 시
    
4. 프로세스가 종료할 때 (`running → terminated`) : **비선점**

<br/>

<br/>

> 비선점 스케줄링
> 
- 아래의 두 경우, CPU를 점유한다
    - CPU가 한 프로세스에 할당되면 프로세스가 종료하든지 (위 상황에서 4번)
    - 또는 대기 상태로 전환해 CPU를 방출하든지! (위 상황에서 1번)

<br/>

<br/>

> 선점 스케줄링
> 
- 데이터가 다수의 프로세스에 의해 공유될 때 **경쟁 조건을 초래**할 수 있다.
- 운영체제 커널 설계에 영향을 줄 수 있다.
    - 시스템 콜을 처리할 동안, 중요한 커널 자료가 변경될 경우 커널이 프로세스를 선점!
    - 단, 이러한 기능을 지원하려면 설계가 복잡해지지만, 비선점 커널은 좋은 모델은 아니다.

<br/>

<br/>

### 디스패처

CPU 스케줄링 기능에 포함된 또 하나의 요소는 **디스패처(dispatcher)**이다.

<br/>

> 디스패처란?
> 
- CPU 코어의 제어를 CPU 스케줄러가 선택한 프로세스에게 주는 모듈
- 아래의 작업들을 포함한다.
    - 프로세스 사이에서의 문맥 교환
    - 사용자 모드로 전환
    - 프로그램을 다시 시작하기 위해 적절한 위치로 이동(jump)

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/dispatch-latency.png" width = 600/>


- 디스패치 지연(`dispatch latency`)란?
    - 디스패처가 하나의 프로세스를 정지하고, 다른 프로세스의 수행을 시작하는데 까지 걸린 시간
    - ***디스패처는 모든 프로세스의 문맥 교환시 호출된다. → 속도가 생명!***
    - 이때, 중요한 건 “문맥 교환이 얼마나 자주 발생하는가?” 이다.

<br/>

<br/>

- Linux에서 제공하는 문맥 교환 횟수를 얻는 명령어 
    ```bash
    $ vmstat 1 3 #1초 지연 단위로 3줄의 출력을 제공!
    ```
    

<br/>

<br/>

- 특정 프로세스에 대한 문맥 교환 횟수를 결정하기
    
    ```bash
    $ cat /proc/2166/status #pid = 2166인 프로세스에 대한 통계를 보기
    
    # 정상 출력 결과
    # voluntary_ctxt_switches 150
    # nonvoluntary_ctxt_switches 8
    ```
    
    
    - 위 결과에서 **자발적 문맥 교환과 비자발적 문맥 교환**의 차이점에 주목하자!
    - ***자발적*** 문맥 교환
        - 현재 사용 불가능한 자원을 요청하여 프로세스가 CPU 제어를 포기한 경우
    - ***비자발적*** 문맥 교환
        - 타임 슬라이스가 만료되었거나 다른 프로세스에게 CPU를 빼았겼을 경우


<br/>

<br/>

# 💡 스케줄링 기준


CPU 스케줄링 알고리즘을 비교하기 위한 여러 기준이 존재한다.

1. **CPU 이용률**(`utilization`)
    1. 가능한 한 CPU를 최대한 바쁘게 유지하기를 원한다.
    
2. **처리량**(`throughput`)
    1. 작업량 측정의 한 방법은 단위 시간당 완료된 프로세스의 개수로, 이를 **처리량**이라고 한다.
    
3. **총처리 시간**(`turnaround time`)
    1. 프로세스를 실행하는 데 소요된 시간이 중요할 수도 있다.
    2. 프로세스의 제출 시간과 완료 시간의 간격을 총처리 시간이라고 한다.
    3. **준비큐에서 대기한 시간 + CPU에서 실행하는 시간 + I/O 시간을 합한 시간**

1. **대기 시간**(`waiting time`)
    1. 스케줄링 알고리즘은 단지 프로세스가 준비 큐에서 대기하는 시간의 양에만 영향을 준다.
    2. **준비큐에서 대기하면서 보낸 시간의 합**

1. **응답 시간**(`response time`)
    1. 대화식 시스템의 경우 총처리 시간이 최선의 기준이 아닐 수 있다.
    2. 따라서 또 다른 기준은 하나의 요구를 제출한 후, **첫 번째 응답이 나올 때까지의 시간**이다.

<br/>

<br/>


> 🌱 CPU 이용률과 처리량을 최대화하고 총처리 시간, 대기 시간, 응답 시간을 최소화하는 것이 바람직!
> 
> 대부분의 경우, 평균 측정 시간을 최적화하려 하지만 때로는 평균보단 최소, 최댓값을 최적화하는 것이 바람직 할 수도 있다!

<br/>

<br/>

# 💡 스케줄링 알고리즘

> CPU 스케줄링은 준비 큐에 있는 어느 프로세스에 CPU 코어를 할당할 것인지를 결정하는 문제를 다룬다.
> 

<br/>


## 선입 선처리 스케줄링 (FCFS: First come, First served Scheduling)

- 가장 간단한 CPU 스케줄링 알고리즘은 **선입 선처리(FCFS) 스케줄링 알고리즘**이다.
    - CPU를 먼저 요청하는 프로세스가 CPU를 먼저 할당받는다.
    - 이 정책의 구현은 FIFO 큐로 쉽게 관리할 수 있다!

<br/>

<br/>


<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/FCFS-gantt.png" width = 600/>



>🌱 선입 선처리 정책에서 평균대기 시간은 일반적으로 최소가 아니다.

<br/>

<br/>

> 추가로 동적 상황에서 선입 선처리 스케줄링의 성능을 고려해보자!
> 
>1. CPU 중심 프로세스가 CPU를 점유하는 동안, 다른 프로세스들은 준비 큐에서 대기한다.
>2. 자신의 작업을 끝낸 프로세스는 I/O 장치로 이동한다.
>3. 모든 I/O 중심 프로세스들은 매우 짧은 CPU 버스트를 가지기에 신속히 끝낸다.
>4. 이후, 준비 큐에서 새로운 CPU 중심 프로세스가 긴 작업을 진행하는 동안 수많은 I/O 프로세스들은 대기한다.
>
>→ 이처럼 **모든 다른 프로세스들이 하나의 긴 프로세스가 CPU를 양도하기를 기다리는 것**을 **호위 효과**라고 한다.

<br/>

<br/>

>🌱 FCFS 스케줄링은 비선점형이라는 것을 주의하자.
>
>대화형 시스템은 각 프로세스가 규칙적인 간격으로 CPU의 몫을 얻는 것이 중요하기 때문에 맞지 않다.


<br/>

<br/>


## 최단 작업 우선 스케줄링 (SJF : Shortest-Job-First Scheduling)

- 최단 작업 우선(SJF) 알고리즘은 각 프로세스에 CPU 버스트 길이를 연관시킨다.
    - CPU가 이용 가능해지면, **가장 작은 CPU 버스트를 가진 프로세스에 할당**한다.


<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/SJF-gantt.png" width = 600/>
    

- SJF 스케줄링 알고리즘은 주어진 프로세스 집합에 대해 최소 평균대기 시간을 줄인다. → **최적임을 증명!**
    - 짧은 프로세스를 긴 프로세스의 앞으로 이동할 수록 평균 대기 시간을 줄일 수 있다.
    - **단, 다음 CPU 버스트의 길이를 알 방법이 없기 때문에 구현할 수 없다.**

<br/>

<br/>

- 한 가지 접근 방식은 SJF 스케줄링과 근사한 방법을 사용하는 것이다!
    - 다음 **CPU 버스트**의 길이를 알 수는 없으나, **그 값을 예측해보는 것이다.**
    - 다음 CPU 버스트가 이전의 버스트와 길이가 비슷하다고 기대하고, 근삿값을 계산하여 짧은 값을 고른다.


<br/>

<br/>

- SJF 알고리즘은 선점형이거나 비선점형일 수 있다.
    - **선점형** : 현재 실행하는 프로세스보다 새로운 프로세스의 버스트가 짧으면 프로세스를 선점
    - **비선점형** : 현재 실행하는 프로세스가 자신의 CPU 버스트를 끝내도록 허용
    - SJF 알고리즘은 때때로 **최소 잔여 시간 우선(shortest remaining time first)** 스케줄링이라 부른다.

<br/>

<br/>

## 라운드 로빈 스케줄링 (Round-Robin Scheduling)

- **라운드 로빈(RR)** 스케줄링 : FCFS와 유사하지만, 프로세스들 사이를 옮겨 다닐 수 있도록 **선점이 추가**된다.
    - 또한 **시간 할당량**, 또는 **타임 슬라이스**라고 하는 작은 단위의 시간을 정의한다.
    
<br/>

<br/>


- 라운드 로빈 스케줄링 구현
    - 준비 큐를 선입선출로 동작하게 만든다.
    - 새로운 프로세스들은 준비 큐의 꼬리에 추가한다.
    - CPU 스케줄러는 준비큐에서 프로세스를 차례대로 선택해 시간 할당량만큼 할당한다.

<br/>

<br/>

**라운드 로빈에서 발생할 수 있는 사례**

1. 프로세스의 CPU 버스트가 시간 할당량보다 작을 경우
    - 프로세스 자신이 CPU를 자발적으로 방출하도록 할 것
    - 이후, 다음 프로세스로 진행하기
2. 실행 중인 프로세스의 CPU 버스트가 시간 할당량보다 긴 경우
    - 타이머가 끝나면 인터럽트가 발생하므로, 문맥교환이 일어나 준비 큐의 꼬리에 다시 넣는다.
    - 이후, CPU 스케줄러는 다음 프로세스를 선택해 진행한다.

<br/>

<br/>


<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/RR-gantt.png" width = 600/>


<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/RR-quantum.png" width = 600/>

> RR 알고리즘의 성능은 시간 할당량의 크기에 매우 많은 영향을 받는다.
> 
- 시간 할당량이 매우 클 경우 → FCFS 정책과 같다.
- 시간 할당량이 매우 작을 경우 → 매우 많은 문맥 교환이 발생, 프로세스의 실행이 느려짐

<br/>

<br/>


<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/RR-turnaround.png" width = 600/>

<br/>

<br/>

> 또한 총처리 시간 또한 시간 할당량의 크기에 좌우된다.
> 
- 한 프로세스 집합의 평균 총처리 시간은 시간 할당량의 크기가 증가해도 반드시 개선되지는 않는다.
    - 일반적으로, 대부분의 프로세스가 단일 시간 할당량 안에 버스트를 끝내야 개선된다.
    - 따라서 CPU 버스트의 80%는 시간 할당량보다 짧아야 한다.

<br/>

<br/>

## 우선순위 스케줄링

- SJF 알고리즘은 일반적인 **우선순위 스케줄링** 알고리즘의 특별한 경우이다!
    - 일반적으로 CPU는 가장 높은 우선순위를 가진 프로세스에 할당된다.
    - 우선순위가 같으면 FCFS 순서로 스케줄된다.

<br/>

<br/>

- 우리가 ***높은*** 우선순위와 ***낮은*** 우선순위에 의해 스케줄링을 논의하고 있음에 유의하자!
    - 일반적으로 0이 최상위 또는 최하위 우선순위인가에 대한 합의는 없다. → 시스템마다 다르다.
    
<br/>

<br/>


<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/prior-gantt.png" width = 600/>
        

<br/>

<br/>

> 우선순위 스케줄링은 선점형이거나 비선점형이 될 수 있다.
> 
- **선점형** : 새로 도착한 프로세스가 현재 실행 중인 프로세스보다 우선 순위가 높으면 선점
- **비선점형** : 단순히 준비완료 큐의 머리 부분에 새로운 프로세스를 넣는다.

<br/>

<br/>

> 우선순위 스케줄링 알고리즘의 주요 문제 : 무한 봉쇄(indefinite blocking) 또는 기아 상태(starvation)
> 
- 실행 준비는 되었으나, 우선 순위가 낮아 무한히 대기하는 경우가 발생할 수 있다!
- 이를 해결하는 방안 : **노화(aging)**
    - **오랫동안 대기하는 프로세스들의 우선순위를 점진적으로 증가시킨다.**

<br/>

<br/>

> 우선순위 스케줄링의 다른 옵션 : ***라운드로빈 + 우선순위 스케줄링***
> 
- 우선 순위가 높은 프로세스를 실행하고, 우선순위가 같으면 라운드 로빈 방식으로 스케줄한다.

<br/>

<br/>

## 다단계 큐 스케줄링

> 큐가 관리되는 방식에 따라 우선순위가 가장 높은 프로세스를 결정하기 위해 O(n) 검색이 필요할 수 있다.
> 

<br/>

<br/>

- 실제로 아래 그림과 같이 우선순위마다 별도의 큐를 갖는 것이 더 쉬울 때도 있다.
    - 우선순위가 가장 높은 큐에서 프로세스를 스케줄 하는 방식으로 동작한다.
    
<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/separate-queue.png" width = 600/>
    

<br/>

<br/>

- **다단계 큐**라고 하는 이 방식은 ***라운드로빈 + 우선순위 스케줄링 방식으로 동작***한다.
    - 프로세스 유형에 따라 프로세스를 여러 개의 개별 큐로 분할하기 위해 사용할 수도 있다.
    - 흔히 **포그라운드**(대화형) 프로세스와 **백그라운드**(배치) 프로세스를 구분한다.
        
        
<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/multilevel-queue.png" width = 600/>
        

<br/>

<br/>

- 위 두 가지 유형의 프로세스는 응답 시간 요구 사항이 달라 스케줄링 요구 사항이 다를 수 있다?
    - 또한 포그라운드 프로세스는 백그라운드 프로세스보다 높은 우선순위를 가질 수 있다.
    - 각 큐에는 자체 스케줄링 알고리즘이 있을 수 있고, 큐와 큐 사이에 스케줄링도 필요하다.

<br/>

<br/>

## 다단계 피드백 큐 스케줄링

- 다단계 큐 스케줄링은 프로세스가 영구적으로 하나의 큐에만 할당된다.
    
    = 다른 큐로 이동하지 않는다 → 오버헤드가 적어 장점이지만 **융통성이 적다!**
    

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/multilevel-feedback-queue.png" width = 600/>

<br/>

<br/>

- ***대조적으로 다단계 피드백 큐 스케줄링은 프로세스가 큐들 사이를 이동하는 것을 허용한다.***
    - 프로세스들을 CPU 버스트 성격에 따라 나눈다.
    - CPU 시간을 너무 많이 사용하는 프로세스 → 낮은 우선순위 큐로 이동!
    - = I/O 중심 프로세스와 대화형 프로세스들을 높은 우선순위 큐로 넣음
    - **마찬가지로, 낮은 우선순위 큐에서 너무 오래 대기하면 높은 우선순위 큐로 이동 → 기아 상태 방지!**

<br/>

<br/>

- 일반적으로 다단계 피드백 큐 스케줄러는 다음의 매개변수에 의해 정의된다.
    - 큐의 개수
    - 각 큐를 위한 스케줄링 알고리즘
    - 한 프로세스를 높은 우선순위 큐로 올려주는 시기를 결정하는 방법
    - 한 프로세스를 낮은 우선순위 큐로 강등시키는 시기를 결정하는 방법
    - 프로세스에 서비스가 필요할 때 프로세스가 들어갈 큐를 결정하는 방법


<br/>

<br/>

# 💡 스레드 스케줄링

## 경쟁 범위

- 사용자 수준과 커널 수준 스레드의 차이 : ***“그들이 어떻게 스케줄 되느냐”***이다.

<br/>

<br/>

- **프로세스 경쟁 범위**(`PCS`)
    - 다대일과 다대다 모델을 구현하는 시스템 환경에서 스레드 라이브러리는 사용자 수준 스레드를 가용한 LWP(경량 프로세스) 상에서 스케줄한다.
    - **동일한 프로세스에 속한 스레드끼리 CPU를 경쟁**

<br/>

<br/>

- **시스템 경쟁 범위**(`SCS`)
    - **CPU 상에 어느 커널 스레드를 스케줄 할 것인지 결정하기 위해 사용**

<br/>

<br/>

>🌱 전형적으로 PCS는 우선순위에 따라 행해진다.
>
>→ 즉, 스케줄러는 가장 높은 우선순위를 가진 실행 가능한 프로세스를 실행한다.
>
>이때, PC는 통상 더 높은 우선순위의 스레드를 위하여 선점한다는 것을 주의해야 한다.

<br/>

<br/>

## PThread 스케줄링

- 스레드를 생성하며 `PCS` 또는 `SCS`를 지정할 수 있는 **POSIX Pthreads API**를 알아보자.
    - Pthreads는 아래와 같은 범위 값을 구분한다.
        - `PTHREAD SCOPE PROCESS` : PCS 스케줄링을 사용
        - `PTHREAD SCOPE SYSTEM` : SCS 스케줄링을 사용

<br/>

<br/>

- Pthread IPC는 경쟁 범위 정책의 정보를 얻어내고 지정하기 위해 아래 두 함수를 제공한다.
    - `pthread attr setscope(pthread attr t *attr, int scope)`
    - `pthread attr getscope(pthread attr t *attr, int *scope)`
    - 첫번째 매개변수 : 스레드를 위한 속성 집합을 가리키는 포인터를 저장
    - 두 번째 매개변수로는 경쟁 범위가 어떻게 지정되는가를 전달


<br/>

<br/>

## 💡 다중 처리기 스케줄링

> 지금까지의 논의는 단일 처리기 코어를 가진 시스템에서 CPU를 스케줄링하는 문제였다.
> 

<br/>

<br/>

- 만일 여러 개의 CPU가 사용 가능하다면?
    
    → 여러 스레드가 병렬로 실행될 수 있으므로 **부하 공유(load sharing)이 가능**해진다!

<br/>

<br/>
    

- 최신 컴퓨팅 시스템에서 다중 처리기는 아래의 시스템 아키텍처들에 사용할 수 있다.
    - 다중 코어 CPU
    - 다중 스레드 코어
    - NUMA 시스템
    - 이기종 다중 처리

<br/>

<br/>

## 다중 처리기 스케줄링에 대한 접근 방법

1. **비대칭 다중 처리(asymmetric multiprocessing)**
    - 하나의 처리기(마스터 서버)가 모든 스케줄링 결정과 다른 시스템의 활동을 취급하게 한다.
    - 오직 하나의 코어만 시스템 자료구조에 접근하여 자료 공유의 필요성을 배제하므로 간단하다!
    - **다만, 마스터 서버가 전체 시스템 성능을 저하시킬 수도 있다는 단점이 있다.**

<br/>

<br/>

1. **대칭 다중 처리(symmetric multi-processing, SMP)**
    - 다중 처리기를 처리하기 위한 표준 접근 방식으로, 각 프로세서는 스스로 스케줄링할 수 있다.
    - 이때, 스케줄 대상이 되는 스레드를 관리하기 위한 두 가지 전략이 있다.
        
        <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/organization-of-ready-queue.png" width = 600/> 
        
        1. 모든 스레드가 공통 준비 큐에 있을 수 있다.
        2. 각 프로세서는 자신만의 스레드 큐를 가진다.

<br/>

<br/>

- ***공통 준비 큐를 가질 경우***
    - 경쟁 조건이 생기지 않도록 두 개의 다른 프로세서가 동일한 스레드를 스케줄 하지 않아야 한다.
        - 이를 위해 경쟁 조건으로부터 락킹 기법의 하나를 사용할 수 있다.
        - 단, 큐에 대한 액세스에는 락 소유권이 필요하므로, 공유 큐의 성능이 저하될 수 있다.

<br/>

<br/>

- ***자신만의 큐를 가질 경우***
    - SMP를 지원하는 시스템에서 가장 일반적인 접근 방식
    - 각 프로세서의 실행 큐는 공유 실행 큐와 관련되어 발생할 수 있는 성능 문제를 겪지 않는다.
    - 또한 자신만의 프로세스별 큐가 있어 캐시 메모리를 보다 효율적으로 사용할 수 있다.
        - **단, 큐마다 부하의 양이 다를 수 있어 신경써야 한다.**

<br/>

<br/>

## 다중 코어 프로세서

> 현대 컴퓨터 하드웨어는 동일한 물리적인 칩 안에 여러 코어를 장착하여 **다중 코어 프로세서**이다.
> 

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/memory-stall.png" width = 600/> 

- 다중 코어 프로세서는 스케줄링 문제를 복잡하게 한다.
    - **메모리 스톨(memory stall)**이란?
    - 프로세서가 메모리에 접근할 때 데이터가 가용해지기를 기다리면서 많은 시간을 허비하는데,
    - 이는 최신 프로세서가 메모리보다 훨씬 빠른 속도로 작동하기 때문이다!

<br/>

<br/>

- 해결법
    
<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/multithreaded-multicore-system.png" width = 600/> 
    
    - 하나의 코어에 2개 이상의 **하드웨어 스레드**를 할당한다.
    - 하나의 하드웨어 스레드가 메모리를 기다리는 동안 다른 스레드로 전환하도록 한다.

<br/>

<br/>


<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/chip-multithreading.png" width = 600/> 

- 위 그림은 **칩 다중 스레딩**으로 알려진 기술이다.
    - 4개의 컴퓨팅 코어가 있고, 각 코어에는 2개의 하드웨어 스레드가 있다.
    - 이를 8개의 논리적 CPU로 볼 수도 있다.
    - Intel 프로세서는 단일 코어에 여러 하드웨어 스레드를 할당하기 위해 **하이퍼-스레딩**을 사용한다고 한다.

<br/>

<br/>

> **처리기를 다중 스레드화하는 2가지 방법**
> 
1. ***거친 다중 스레딩***
    1. 긴 지연시간을 가진 이벤트가 발생할 때까지 한 코어에서 수행된다.
    2. 프로세스 코어에서 다른 스레드가 수행되기 전에 명령어 파이프라인이 정리되어야 한다.
        
        → 스레드 간 교환 비용이 많이 든다.
        
<br/>

<br/>

    
2. ***세밀한 다중 스레딩***
    - 보통 명령어 주기의 경계에서 같이 좀 더 세밀한 정밀도를 가진  시점에서 스레드 교환이 일어난다.
    - 스레드 교환을 위한 회로를 포함한다.
        
        →  스레드 간 교환 비용이 적어진다.
        

<br/>

<br/>

<img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/two-level-scheduling.png" width = 600/> 

- 다중 스레드 다중 코어 프로세서는 위 그림처럼 다른 스케줄링 단계가 필요하다.
    - 1단계 : 소프트웨어 스레드를 선택할 때 결정해야 하는 스케줄링을 결정
    - 2단계 : 각 코어가 실행할 하드웨어 스레드를 결정하는 방법을 명시
        - 명시하는 방법에는 크게 2가지 방법이 있다.
        - 첫번째 방법 : 간단한 RR을 사용해 처리 코어에 하드웨어 스레드를 스케줄
        - 두번째 방법 : 코어당 2개의 하드웨어 스레드를 가진 이중 코어 프로세서를 사용
            
            → 이때 각 하드웨어 스레드는 0~7까지의 동적 **긴급도**가 배정된다.
            
<br/>

<br/>


## 부하 균등화

> SMP에서 처리기가 하나 이상인 것을 활용하려면, **부하를 균등하게 배분하는 것이 매우 중요**하다!
> 

<br/>

<br/>

- ***부하 균등화(load balancing)***이란?
    - SMP에서 모든 처리기 사이에 부하가 고르게 배분되도록 시도하는 것.
    - **push 이주**와 **pull 이주** 방식이 존재한다.

<br/>

<br/>

- push 이주
    - 특정 태스크가 주기적으로 부하를 검사하고, 과부하인 처리기의 부하를 덜 바쁜 처리기로 스레드를 이동시킴!

<br/>

<br/>

- pull 이주
    - 쉬고 있는 처리기가 바쁜 처리기를 기다리고 있는 프로세스를 Pull하는 것을 말한다.

<br/>

<br/>

## 처리기 선호도

> 스레드가 다른 처리기로 이주한다면 캐시 메모리에는 어떤 일이 벌어질까?
> 

1. 첫번째 프로세서의 캐시 메모리의 내용은 무효화되어야 한다.
2. 두번째 프로세서의 캐시는 다시 채워져야 한다.

<br/>

→ 캐시 무효화 및 다시 채우는 비용은 많이 든다!

→ 따라서 스레드를 이주시키지 않고 같은 프로세서에서 계속 실행시키면서 *warm cache*를 이용하려고 한다.

→ 이를 **프로세서 선호도**라고 한다.

<br/>

<br/>

- 처리기 선호도는 여러 형태를 띤다.
    - **약한 선호도** : OS가 동일 처리기에서 프로세서는 실행하려는 정책을 가지고 있지만 보장하지는 않을 때
        - 이 경우, 프로세스가 처리기 사이에서 이주하는 것이 가능하다.
    - **강한 선호도** : 프로세서를 실행하려는 정책을 보장할 때

<br/>

<br/>

- 메인 메모리 아키텍처는 프로세서 선호도 문제에도 영향을 줄 수 있다.
    
    <img src="https://github.com/2dongyeop/TIL/blob/main/OS/image/NUMA-and-CPU-scheduling.png" width = 600/> 

    - **부하 균등은 종종 프로세서 선호도의 이점을 상쇄한다!**
    - 즉, 동일한 프로세서에서 스레드를 계속 실행 → 해당 프로세서의 캐시를 계속 사용하는 이점
        - 따라서 부하를 균등하게 조정하면 이러한 이점이 사라진다.

<br/>

<br/>

## 이기종 다중 처리

- **이기종 다중 처리**(`heoerogeneous multiprocessings`, HMP)란?
    - 동일한 명령어 집합을 실행하지만, 전력 소비를 유휴 수준으로 저정하는 기능을 포함하여
    - 클록 속도 및 전력 관리 측면에서 차이가 나는 코어를 사용하여 설계된 방식
    - **작업의 특정 요구에 따라 특정 코어에 특정 작업을 할당하여 전력 소비를 더 잘 관리하는 것이 목표**

<br/>

<br/>

- HMP의 장점
    - 백그라운드 작업같은 긴 시간동안 실행해야 하는 작업을 little 코어에 할당해 배터리 충전을 보존한다.
    - 짧은 기간 동안 실행될 수 있는 대화형 응용 프로그램을 big 코어에 할당할 수 있다.

<br/>

<br/>
